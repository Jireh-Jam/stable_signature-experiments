# Outputs Directory

This directory contains all results generated by the watermark robustness testing pipeline.

## Structure

```
outputs/
├── watermark_anything/         # Watermark Anything results
│   ├── transformed_images/    # Transformed test images
│   │   ├── resize/           # Resized images
│   │   ├── crop/             # Cropped images
│   │   ├── rotation/         # Rotated images
│   │   ├── blur/             # Blurred images
│   │   ├── compression/      # JPEG compressed images
│   │   ├── noise/            # Images with added noise
│   │   └── colour_jitter/    # Colour-modified images
│   └── results/              # CSV files and visualisations
│       ├── watermark_detection_results_Watermark_Anything.csv
│       └── results_visualisation_Watermark_Anything.png
│
├── trustmark/                 # TrustMark results
│   ├── transformed_images/
│   └── results/
│
└── stable_signature/          # Stable Signature results
    ├── transformed_images/
    └── results/
```

## Results Files

### CSV Results

Each method generates a CSV file containing:

| Column | Description |
|--------|-------------|
| `original_image` | Name of the original watermarked image |
| `transformed_image` | Name of the transformed image |
| `transformation_type` | Type of transformation applied (resize, crop, etc.) |
| `watermark_detected` | Boolean indicating if watermark was detected |
| `detected_bits` | The actual watermark bits extracted |
| `num_bits_detected` | Number of bits detected |
| `psnr` | Peak Signal-to-Noise Ratio (image quality metric) |
| `ssim` | Structural Similarity Index (similarity metric) |
| `mse` | Mean Squared Error (difference metric) |

### Visualisation Files

PNG images showing:
1. Detection rate by transformation type
2. PSNR distribution histogram
3. SSIM distribution histogram
4. Scatter plot of detection vs image quality

## Understanding the Metrics

### Image Quality Metrics

**PSNR (Peak Signal-to-Noise Ratio)**
- Measured in decibels (dB)
- Higher is better
- Typical values: 20-50 dB
- > 40 dB: Excellent quality, barely perceptible difference
- 30-40 dB: Good quality, minor visible differences
- < 30 dB: Noticeable degradation

**SSIM (Structural Similarity Index)**
- Range: 0 to 1
- Higher is better
- 1.0: Identical images
- > 0.95: Very similar
- 0.80-0.95: Similar
- < 0.80: Noticeable structural differences

**MSE (Mean Squared Error)**
- Lower is better
- 0: Identical images
- Higher values indicate more difference

### Detection Metrics

**Detection Rate**
- Percentage of images where watermark was successfully detected
- 100%: Watermark survived all transformations
- 50-99%: Partial robustness
- < 50%: Poor robustness for this transformation

## Using the Results

### Analysing Detection Robustness

1. **Open the CSV file** in your preferred spreadsheet application
2. **Filter by transformation type** to see which transformations affect detection most
3. **Compare detection rates** across different transformation parameters
4. **Correlate with quality metrics** to understand the trade-off

### Comparing Methods

Run the pipeline for each method and compare:
- Overall detection rates
- Robustness to specific transformations
- Image quality preservation
- Processing speed

### Example Analysis Queries

**Which transformation is most destructive?**
```python
import pandas as pd

df = pd.read_csv('outputs/trustmark/results/watermark_detection_results_TrustMark.csv')
detection_by_type = df.groupby('transformation_type')['watermark_detected'].mean()
print(detection_by_type.sort_values())
```

**What's the relationship between compression quality and detection?**
```python
compression_results = df[df['transformation_type'] == 'compression']
print(compression_results[['transformed_image', 'watermark_detected', 'psnr', 'ssim']])
```

**How does image quality correlate with detection?**
```python
import matplotlib.pyplot as plt

detected = df[df['watermark_detected'] == True]
not_detected = df[df['watermark_detected'] == False]

plt.scatter(detected['ssim'], detected['psnr'], label='Detected', alpha=0.5)
plt.scatter(not_detected['ssim'], not_detected['psnr'], label='Not Detected', alpha=0.5)
plt.xlabel('SSIM')
plt.ylabel('PSNR (dB)')
plt.legend()
plt.show()
```

## Disk Space Management

The outputs directory can grow quite large:
- Each transformed image: ~0.5-5 MB (depending on resolution)
- For 100 original images with all transformations: ~2-10 GB

**To save space:**
1. Process images in batches
2. Delete transformed images after analysis (keep CSV files)
3. Compress results directories when archiving

**To clean up:**
```bash
# Remove all transformed images (keep results)
find outputs/*/transformed_images -type f -delete

# Remove everything for a specific method
rm -rf outputs/trustmark/*

# Archive results before cleaning
tar -czf results_backup_$(date +%Y%m%d).tar.gz outputs/*/results/
```

## Sharing Results

### For Collaboration

Share the CSV files and visualisations:
```bash
# Create a shareable archive
tar -czf results_watermark_analysis.tar.gz outputs/*/results/
```

### For Publications

The CSV files can be imported into:
- Microsoft Excel
- Google Sheets
- MATLAB
- R
- Python (pandas)

The visualisations are publication-ready PNG images at 300 DPI.

## Troubleshooting

**Empty results directory**
- Check that the pipeline completed successfully
- Verify images exist in the raw images directory
- Review notebook output for errors

**Missing visualisations**
- Ensure matplotlib is installed
- Check that the visualisation cell executed without errors
- Verify results DataFrame is not empty

**CSV file not opening**
- Check file isn't corrupted (should be plain text)
- Try opening with a different application
- Verify the file size is non-zero

## Archiving Results

For long-term storage, we recommend:

1. **Keep**: CSV files and visualisations
2. **Optional**: A representative sample of transformed images
3. **Can delete**: Most transformed images (reproducible from pipeline)

Archive command:
```bash
# Archive results with metadata
tar -czf watermark_analysis_$(date +%Y%m%d).tar.gz \
    outputs/*/results/ \
    pipeline_mk4.ipynb \
    README.md
```

---

For more information, see the main [README.md](../README.md) or [QUICKSTART.md](../QUICKSTART.md).
