{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Watermark Robustness Testing Pipeline\n",
        "\n",
        "## Welcome!\n",
        "\n",
        "This notebook allows you to test how well watermarks survive various image transformations. You don't need to be a technical expert to use this tool.\n",
        "\n",
        "### What Does This Notebook Do?\n",
        "\n",
        "1. **Loads watermarked images** - Brings in images that already have watermarks embedded\n",
        "2. **Applies transformations** - Modifies the images (resize, crop, blur, etc.)\n",
        "3. **Tests watermark detection** - Checks if the watermark can still be found after transformation\n",
        "4. **Generates reports** - Creates CSV files with the results for analysis\n",
        "\n",
        "### Supported Watermarking Methods\n",
        "\n",
        "- **Stable Signature** - Watermarks embedded in latent diffusion models\n",
        "- **Watermark Anything** - General-purpose watermarking system\n",
        "- **TrustMark** - Robust watermarking with quality-factor tuning\n",
        "\n",
        "### How to Use This Notebook\n",
        "\n",
        "**Please read the instructions in each section before running the code.** Do not simply click \"Run All\" - some sections require configuration first.\n",
        "\n",
        "ğŸ’¡ **Tip**: Look for cells marked with âš™ï¸ (configuration) or â–¶ï¸ (action required)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## âš™ï¸ Section 1: Configuration Settings\n",
        "\n",
        "### Important: Please Update These Settings\n",
        "\n",
        "Before running any other cells, you must configure the settings below to match your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIGURATION: Choose Your Watermarking Method\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# \n",
        "# Please select ONE watermarking method to test by uncommenting the appropriate line:\n",
        "#\n",
        "# Options:\n",
        "#   - \"Stable_Signature\"      : For images watermarked with Stable Signature\n",
        "#   - \"Watermark_Anything\"    : For images watermarked with Watermark Anything\n",
        "#   - \"TrustMark\"             : For images watermarked with TrustMark\n",
        "#\n",
        "# Note: This notebook processes one method at a time. To test multiple methods,\n",
        "#       run the notebook separately for each one.\n",
        "\n",
        "WATERMARK_METHOD = \"Watermark_Anything\"  # â† Change this to your method\n",
        "# WATERMARK_METHOD = \"TrustMark\"\n",
        "# WATERMARK_METHOD = \"Stable_Signature\"\n",
        "\n",
        "print(f\"âœ“ Selected watermarking method: {WATERMARK_METHOD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIGURATION: Directory Paths\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#\n",
        "# These paths tell the notebook where to find files and save results.\n",
        "# \n",
        "# If you're using Azure AI:\n",
        "#   - Change 'YourName' to your actual username\n",
        "#   - The default paths should work once you've cloned the repository\n",
        "#\n",
        "# If you're running locally:\n",
        "#   - Modify these paths to match your local directory structure\n",
        "\nimport os\n",
        "\n",
        "# â”€â”€â”€ Azure AI Settings â”€â”€â”€\n",
        "USER_NAME = 'YourName'  # â† CHANGE THIS to your Azure AI username\n",
        "AZURE_ROOT = '/home/azureuser/cloudfiles/code/Users/'\n",
        "IS_AZURE = os.path.exists(AZURE_ROOT)  # Auto-detect if running on Azure\n",
        "\n",
        "# â”€â”€â”€ Path Configuration â”€â”€â”€\n",
        "if IS_AZURE:\n",
        "    ROOT_DIR = os.path.join(AZURE_ROOT, USER_NAME)\n",
        "    print(f\"âœ“ Running on Azure AI with root directory: {ROOT_DIR}\")\n",
        "else:\n",
        "    # Local development - use current working directory\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    print(f\"âœ“ Running locally with root directory: {ROOT_DIR}\")\n",
        "\n",
        "# Verify the directory exists\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    print(f\"âš ï¸  WARNING: Root directory does not exist: {ROOT_DIR}\")\n",
        "    print(f\"   Please update USER_NAME or ROOT_DIR paths above.\")\n",
        "else:\n",
        "    print(f\"âœ“ Root directory confirmed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIGURATION: Method-Specific Paths\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#\n",
        "# Each watermarking method requires different files and directories.\n",
        "# These paths are automatically set based on your chosen method.\n",
        "# You may need to adjust these if your repository structure differs.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# â”€â”€â”€ Repository Structure â”€â”€â”€\n",
        "REPO_DIR = Path(ROOT_DIR) / \"ost-embedding-research\"\n",
        "WATERMARK_MODELS_DIR = REPO_DIR / \"watermark_models\"\n",
        "\n",
        "# â”€â”€â”€ Method-Specific Configuration â”€â”€â”€\n",
        "if WATERMARK_METHOD == \"Watermark_Anything\":\n",
        "    METHOD_DIR = WATERMARK_MODELS_DIR / \"watermark-anything\"\n",
        "    RAW_IMAGES_PATH = METHOD_DIR / \"output\" / \"imgs_w\"\n",
        "    CHECKPOINT_PATH = METHOD_DIR / \"models\" / \"watermark_anything_model.pth\"\n",
        "    OUTPUT_DIR = REPO_DIR / \"outputs\" / \"watermark_anything\"\n",
        "    \n",
        "elif WATERMARK_METHOD == \"TrustMark\":\n",
        "    METHOD_DIR = WATERMARK_MODELS_DIR / \"trustmark\"\n",
        "    RAW_IMAGES_PATH = METHOD_DIR / \"watermarked_images\"\n",
        "    CHECKPOINT_PATH = None  # TrustMark uses built-in models\n",
        "    OUTPUT_DIR = REPO_DIR / \"outputs\" / \"trustmark\"\n",
        "    \n",
        "elif WATERMARK_METHOD == \"Stable_Signature\":\n",
        "    METHOD_DIR = WATERMARK_MODELS_DIR / \"stable-signature\"\n",
        "    RAW_IMAGES_PATH = METHOD_DIR / \"watermarked_images\"\n",
        "    CHECKPOINT_PATH = METHOD_DIR / \"models\" / \"dec_48b_whit.torchscript.pt\"\n",
        "    OUTPUT_DIR = REPO_DIR / \"outputs\" / \"stable_signature\"\n",
        "\n",
        "# â”€â”€â”€ Create Output Directories â”€â”€â”€\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TRANSFORMED_IMAGES_DIR = OUTPUT_DIR / \"transformed_images\"\n",
        "RESULTS_DIR = OUTPUT_DIR / \"results\"\n",
        "TRANSFORMED_IMAGES_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"âœ“ Configuration for {WATERMARK_METHOD}:\")\n",
        "print(f\"  - Method directory: {METHOD_DIR}\")\n",
        "print(f\"  - Raw images: {RAW_IMAGES_PATH}\")\n",
        "print(f\"  - Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"  - Checkpoint: {CHECKPOINT_PATH if CHECKPOINT_PATH else 'Built-in model'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# CONFIGURATION: Processing Options\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#\n",
        "# Control how many images to process and which transformations to apply.\n",
        "# Start with small numbers for testing, then increase for full analysis.\n",
        "\n",
        "# â”€â”€â”€ Number of Images to Process â”€â”€â”€\n",
        "# Set to None to process all images, or specify a number for testing\n",
        "MAX_IMAGES_TO_PROCESS = 10  # â† Start with 10 images for testing\n",
        "# MAX_IMAGES_TO_PROCESS = None  # â† Uncomment to process all images\n",
        "\n",
        "# â”€â”€â”€ Transformations to Apply â”€â”€â”€\n",
        "# Enable or disable specific transformation types\n",
        "APPLY_RESIZE = True          # Resize images to different dimensions\n",
        "APPLY_CROP = True            # Crop images (centre crop with various percentages)\n",
        "APPLY_ROTATION = True        # Rotate images by various angles\n",
        "APPLY_BLUR = True            # Apply Gaussian blur with different strengths\n",
        "APPLY_COMPRESSION = True     # JPEG compression at different quality levels\n",
        "APPLY_NOISE = True           # Add Gaussian noise\n",
        "APPLY_COLOUR_JITTER = True   # Adjust brightness, contrast, saturation\n",
        "\n",
        "# â”€â”€â”€ Transformation Parameters â”€â”€â”€\n",
        "RESIZE_DIMENSIONS = [(256, 256), (512, 512), (1024, 1024)]\n",
        "CROP_PERCENTAGES = [0.99, 0.90, 0.80, 0.70, 0.60, 0.50]\n",
        "ROTATION_ANGLES = [5, 15, 30, 45, 90, 180]\n",
        "BLUR_KERNEL_SIZES = [3, 11, 21, 51]\n",
        "COMPRESSION_QUALITIES = [95, 85, 75, 50, 25]\n",
        "\n",
        "print(\"âœ“ Processing configuration set:\")\n",
        "print(f\"  - Maximum images: {MAX_IMAGES_TO_PROCESS if MAX_IMAGES_TO_PROCESS else 'All'}\")\n",
        "print(f\"  - Transformations enabled: \", end=\"\")\n",
        "enabled = [name for name, enabled in [\n",
        "    (\"Resize\", APPLY_RESIZE),\n",
        "    (\"Crop\", APPLY_CROP),\n",
        "    (\"Rotation\", APPLY_ROTATION),\n",
        "    (\"Blur\", APPLY_BLUR),\n",
        "    (\"Compression\", APPLY_COMPRESSION),\n",
        "    (\"Noise\", APPLY_NOISE),\n",
        "    (\"Colour Jitter\", APPLY_COLOUR_JITTER)\n",
        "] if enabled]\n",
        "print(\", \".join(enabled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“¦ Section 2: Install Dependencies\n",
        "\n",
        "This section installs the required Python packages. These packages enable watermark detection and image processing.\n",
        "\n",
        "**You only need to run this once per environment.** If you've already installed the packages, you can skip this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Install Required Packages\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "#\n",
        "# This cell checks for required packages and installs them if missing.\n",
        "# The installation may take a few minutes on first run.\n",
        "\n",
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_if_missing(package_name, import_name=None):\n",
        "    \"\"\"Install a package if it's not already available.\"\"\"\n",
        "    if import_name is None:\n",
        "        import_name = package_name\n",
        "    \n",
        "    if importlib.util.find_spec(import_name) is None:\n",
        "        print(f\"ğŸ“¥ Installing {package_name}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name])\n",
        "        print(f\"âœ“ {package_name} installed successfully\")\n",
        "    else:\n",
        "        print(f\"âœ“ {package_name} already installed\")\n",
        "\n",
        "# Core dependencies\n",
        "print(\"Checking and installing dependencies...\\n\")\n",
        "install_if_missing(\"torch\")\n",
        "install_if_missing(\"torchvision\")\n",
        "install_if_missing(\"Pillow\", \"PIL\")\n",
        "install_if_missing(\"numpy\")\n",
        "install_if_missing(\"opencv-python\", \"cv2\")\n",
        "install_if_missing(\"scikit-image\", \"skimage\")\n",
        "install_if_missing(\"pandas\")\n",
        "install_if_missing(\"matplotlib\")\n",
        "install_if_missing(\"tqdm\")\n",
        "\n",
        "# Method-specific dependencies\n",
        "if WATERMARK_METHOD == \"Watermark_Anything\":\n",
        "    install_if_missing(\"timm\")\n",
        "elif WATERMARK_METHOD == \"TrustMark\":\n",
        "    install_if_missing(\"trustmark\")\n",
        "elif WATERMARK_METHOD == \"Stable_Signature\":\n",
        "    install_if_missing(\"omegaconf\")\n",
        "    install_if_missing(\"einops\")\n",
        "\n",
        "print(\"\\nâœ“ All dependencies are installed and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ”§ Section 3: Import Libraries and Utilities\n",
        "\n",
        "This section imports all the necessary Python libraries and custom functions for the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Import Required Libraries\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "# Image processing\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add repository directories to path\n",
        "sys.path.insert(0, str(REPO_DIR))\n",
        "sys.path.insert(0, str(METHOD_DIR))\n",
        "\n",
        "print(\"âœ“ Libraries imported successfully\")\n",
        "print(f\"âœ“ Using PyTorch version: {torch.__version__}\")\n",
        "print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ” Section 4: Load Watermark Detection Model\n",
        "\n",
        "This section loads the appropriate watermark detection model based on your chosen method.\n",
        "\n",
        "Each watermarking method has its own detection system:\n",
        "- **Stable Signature**: Uses a pre-trained decoder model\n",
        "- **Watermark Anything**: Loads a checkpoint and uses message prediction\n",
        "- **TrustMark**: Uses the built-in TrustMark library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Load Watermark Detection Model\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if WATERMARK_METHOD == \"Watermark_Anything\":\n",
        "    print(\"Loading Watermark Anything model...\")\n",
        "    \n",
        "    # Import method-specific modules\n",
        "    from watermark_anything.data.metrics import msg_predict_inference\n",
        "    from notebooks.inference import load_model_from_checkpoint\n",
        "    \n",
        "    # Load the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = load_model_from_checkpoint(str(CHECKPOINT_PATH), device=device)\n",
        "    model.eval()\n",
        "    \n",
        "    def detect_watermark(image_path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Detect and return the watermark bits from an image.\n",
        "        \n",
        "        Args:\n",
        "            image_path: Path to the watermarked image\n",
        "            \n",
        "        Returns:\n",
        "            Array of detected watermark bits (0s and 1s)\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = TF.to_tensor(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            detected_bits = msg_predict_inference(model, image_tensor)\n",
        "        \n",
        "        return detected_bits.cpu().numpy()\n",
        "    \n",
        "    print(\"âœ“ Watermark Anything model loaded successfully\")\n",
        "\n",
        "elif WATERMARK_METHOD == \"TrustMark\":\n",
        "    print(\"Loading TrustMark model...\")\n",
        "    \n",
        "    from trustmark import TrustMark\n",
        "    \n",
        "    # Initialise TrustMark with quality model\n",
        "    trustmark_model = TrustMark(verbose=False, model_type='Q')\n",
        "    \n",
        "    def detect_watermark(image_path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Detect and return the watermark bits from an image using TrustMark.\n",
        "        \n",
        "        Args:\n",
        "            image_path: Path to the watermarked image\n",
        "            \n",
        "        Returns:\n",
        "            Array of detected watermark bits (0s and 1s)\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        detected_bits, _ = trustmark_model.decode(image)\n",
        "        return np.array(detected_bits)\n",
        "    \n",
        "    print(\"âœ“ TrustMark model loaded successfully\")\n",
        "\n",
        "elif WATERMARK_METHOD == \"Stable_Signature\":\n",
        "    print(\"Loading Stable Signature model...\")\n",
        "    \n",
        "    # Import method-specific modules\n",
        "    from hidden.utils import get_watermarking_mask\n",
        "    \n",
        "    # Load the decoder model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    decoder = torch.jit.load(str(CHECKPOINT_PATH)).to(device)\n",
        "    decoder.eval()\n",
        "    \n",
        "    def detect_watermark(image_path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Detect and return the watermark bits from an image using Stable Signature.\n",
        "        \n",
        "        Args:\n",
        "            image_path: Path to the watermarked image\n",
        "            \n",
        "        Returns:\n",
        "            Array of detected watermark bits (0s and 1s)\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = TF.to_tensor(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            detected_bits = decoder(image_tensor)\n",
        "        \n",
        "        return (detected_bits.cpu().numpy() > 0).astype(int).flatten()\n",
        "    \n",
        "    print(\"âœ“ Stable Signature model loaded successfully\")\n",
        "\n",
        "print(f\"\\nâœ“ Detection function ready: detect_watermark()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ–¼ï¸ Section 5: Image Transformation Functions\n",
        "\n",
        "This section defines functions to apply various transformations to images. Each transformation tests how well the watermark survives different types of image manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Image Transformation Functions\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "class ImageTransformations:\n",
        "    \"\"\"Collection of image transformation functions for watermark robustness testing.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def resize(image: Image.Image, width: int, height: int) -> Image.Image:\n",
        "        \"\"\"Resize image to specified dimensions.\"\"\"\n",
        "        return image.resize((width, height), Image.Resampling.LANCZOS)\n",
        "    \n",
        "    @staticmethod\n",
        "    def centre_crop(image: Image.Image, percentage: float) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Crop image from the centre, keeping specified percentage of the original.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            percentage: Percentage of image to keep (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        width, height = image.size\n",
        "        new_width = int(width * percentage)\n",
        "        new_height = int(height * percentage)\n",
        "        \n",
        "        left = (width - new_width) // 2\n",
        "        top = (height - new_height) // 2\n",
        "        right = left + new_width\n",
        "        bottom = top + new_height\n",
        "        \n",
        "        return image.crop((left, top, right, bottom))\n",
        "    \n",
        "    @staticmethod\n",
        "    def rotate(image: Image.Image, angle: float) -> Image.Image:\n",
        "        \"\"\"Rotate image by specified angle (degrees).\"\"\"\n",
        "        return image.rotate(angle, expand=True, fillcolor=(255, 255, 255))\n",
        "    \n",
        "    @staticmethod\n",
        "    def gaussian_blur(image: Image.Image, kernel_size: int) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Apply Gaussian blur to image.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            kernel_size: Size of the Gaussian kernel (must be odd)\n",
        "        \"\"\"\n",
        "        # Convert PIL to numpy for OpenCV\n",
        "        img_array = np.array(image)\n",
        "        blurred = cv2.GaussianBlur(img_array, (kernel_size, kernel_size), 0)\n",
        "        return Image.fromarray(blurred)\n",
        "    \n",
        "    @staticmethod\n",
        "    def jpeg_compression(image: Image.Image, quality: int) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Apply JPEG compression at specified quality level.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            quality: JPEG quality (1-100, higher is better quality)\n",
        "        \"\"\"\n",
        "        from io import BytesIO\n",
        "        buffer = BytesIO()\n",
        "        image.save(buffer, format='JPEG', quality=quality)\n",
        "        buffer.seek(0)\n",
        "        return Image.open(buffer)\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_noise(image: Image.Image, noise_level: float = 0.02) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Add Gaussian noise to image.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            noise_level: Standard deviation of noise (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        img_array = np.array(image).astype(np.float32) / 255.0\n",
        "        noise = np.random.normal(0, noise_level, img_array.shape)\n",
        "        noisy_img = np.clip(img_array + noise, 0, 1)\n",
        "        return Image.fromarray((noisy_img * 255).astype(np.uint8))\n",
        "    \n",
        "    @staticmethod\n",
        "    def colour_jitter(image: Image.Image, brightness: float = 0.2, \n",
        "                     contrast: float = 0.2, saturation: float = 0.2) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Randomly change brightness, contrast, and saturation.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            brightness: Brightness jitter factor (0.0 to 1.0)\n",
        "            contrast: Contrast jitter factor (0.0 to 1.0)\n",
        "            saturation: Saturation jitter factor (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        jitter = transforms.ColorJitter(\n",
        "            brightness=brightness,\n",
        "            contrast=contrast,\n",
        "            saturation=saturation\n",
        "        )\n",
        "        return jitter(image)\n",
        "\n",
        "# Create instance for easy access\n",
        "transform = ImageTransformations()\n",
        "\n",
        "print(\"âœ“ Image transformation functions loaded\")\n",
        "print(\"  Available transformations:\")\n",
        "print(\"  - resize()\")\n",
        "print(\"  - centre_crop()\")\n",
        "print(\"  - rotate()\")\n",
        "print(\"  - gaussian_blur()\")\n",
        "print(\"  - jpeg_compression()\")\n",
        "print(\"  - add_noise()\")\n",
        "print(\"  - colour_jitter()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ¯ Section 6: Apply Transformations to Images\n",
        "\n",
        "### â–¶ï¸ Action Required\n",
        "\n",
        "This section applies all enabled transformations to your watermarked images. \n",
        "\n",
        "**Important Notes:**\n",
        "- This process may take considerable time depending on the number of images and transformations\n",
        "- We recommend testing with a small number of images first (set `MAX_IMAGES_TO_PROCESS = 10` above)\n",
        "- Results are saved to separate subdirectories for each transformation type\n",
        "- You can monitor progress with the progress bars displayed during processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Apply All Transformations\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def apply_transformations_to_dataset():\n",
        "    \"\"\"\n",
        "    Apply all enabled transformations to the dataset of watermarked images.\n",
        "    Creates subdirectories for each transformation type and saves results.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get list of images to process\n",
        "    image_files = sorted([f for f in os.listdir(RAW_IMAGES_PATH) \n",
        "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "    \n",
        "    if MAX_IMAGES_TO_PROCESS:\n",
        "        image_files = image_files[:MAX_IMAGES_TO_PROCESS]\n",
        "    \n",
        "    print(f\"Processing {len(image_files)} images...\\n\")\n",
        "    \n",
        "    # Counter for total transformations\n",
        "    transformation_count = 0\n",
        "    \n",
        "    # Process each image\n",
        "    for image_name in tqdm(image_files, desc=\"Processing images\"):\n",
        "        image_path = os.path.join(RAW_IMAGES_PATH, image_name)\n",
        "        base_name = Path(image_name).stem\n",
        "        \n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            \n",
        "            # â”€â”€â”€ Resize Transformations â”€â”€â”€\n",
        "            if APPLY_RESIZE:\n",
        "                resize_dir = TRANSFORMED_IMAGES_DIR / \"resize\"\n",
        "                resize_dir.mkdir(exist_ok=True)\n",
        "                for width, height in RESIZE_DIMENSIONS:\n",
        "                    resized = transform.resize(image, width, height)\n",
        "                    output_path = resize_dir / f\"{base_name}_resize_{width}x{height}.png\"\n",
        "                    resized.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # â”€â”€â”€ Centre Crop Transformations â”€â”€â”€\n",
        "            if APPLY_CROP:\n",
        "                crop_dir = TRANSFORMED_IMAGES_DIR / \"crop\"\n",
        "                crop_dir.mkdir(exist_ok=True)\n",
        "                for percentage in CROP_PERCENTAGES:\n",
        "                    cropped = transform.centre_crop(image, percentage)\n",
        "                    output_path = crop_dir / f\"{base_name}_crop_{int(percentage*100)}pct.png\"\n",
        "                    cropped.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # â”€â”€â”€ Rotation Transformations â”€â”€â”€\n",
        "            if APPLY_ROTATION:\n",
        "                rotation_dir = TRANSFORMED_IMAGES_DIR / \"rotation\"\n",
        "                rotation_dir.mkdir(exist_ok=True)\n",
        "                for angle in ROTATION_ANGLES:\n",
        "                    rotated = transform.rotate(image, angle)\n",
        "                    output_path = rotation_dir / f\"{base_name}_rotate_{angle}deg.png\"\n",
        "                    rotated.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # â”€â”€â”€ Blur Transformations â”€â”€â”€\n",
        "            if APPLY_BLUR:\n",
        "                blur_dir = TRANSFORMED_IMAGES_DIR / \"blur\"\n",
        "                blur_dir.mkdir(exist_ok=True)\n",
        "                for kernel_size in BLUR_KERNEL_SIZES:\n",
        "                    blurred = transform.gaussian_blur(image, kernel_size)\n",
        "                    output_path = blur_dir / f\"{base_name}_blur_k{kernel_size}.png\"\n",
        "                    blurred.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # â”€â”€â”€ Compression Transformations â”€â”€â”€\n",
        "            if APPLY_COMPRESSION:\n",
        "                compression_dir = TRANSFORMED_IMAGES_DIR / \"compression\"\n",
        "                compression_dir.mkdir(exist_ok=True)\n",
        "                for quality in COMPRESSION_QUALITIES:\n",
        "                    compressed = transform.jpeg_compression(image, quality)\n",
        "                    output_path = compression_dir / f\"{base_name}_jpeg_q{quality}.jpg\"\n",
        "                    compressed.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # â”€â”€â”€ Noise Transformations â”€â”€â”€\n",
        "            if APPLY_NOISE:\n",
        "                noise_dir = TRANSFORMED_IMAGES_DIR / \"noise\"\n",
        "                noise_dir.mkdir(exist_ok=True)\n",
        "                noisy = transform.add_noise(image)\n",
        "                output_path = noise_dir / f\"{base_name}_noise.png\"\n",
        "                noisy.save(output_path)\n",
        "                transformation_count += 1\n",
        "            \n",
        "            # â”€â”€â”€ Colour Jitter Transformations â”€â”€â”€\n",
        "            if APPLY_COLOUR_JITTER:\n",
        "                jitter_dir = TRANSFORMED_IMAGES_DIR / \"colour_jitter\"\n",
        "                jitter_dir.mkdir(exist_ok=True)\n",
        "                jittered = transform.colour_jitter(image)\n",
        "                output_path = jitter_dir / f\"{base_name}_jitter.png\"\n",
        "                jittered.save(output_path)\n",
        "                transformation_count += 1\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"\\nâš ï¸  Error processing {image_name}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    print(f\"\\nâœ“ Transformation complete!\")\n",
        "    print(f\"  - Processed {len(image_files)} images\")\n",
        "    print(f\"  - Created {transformation_count} transformed images\")\n",
        "    print(f\"  - Results saved to: {TRANSFORMED_IMAGES_DIR}\")\n",
        "\n",
        "# Run the transformation process\n",
        "apply_transformations_to_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“Š Section 7: Calculate Image Quality Metrics\n",
        "\n",
        "This section defines functions to calculate various image quality metrics. These metrics help quantify how much the transformations have altered the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Image Quality Metrics\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "class ImageMetrics:\n",
        "    \"\"\"Calculate various image quality and similarity metrics.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_psnr(original: np.ndarray, modified: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculate Peak Signal-to-Noise Ratio (PSNR).\n",
        "        Higher values indicate better quality (less distortion).\n",
        "        \"\"\"\n",
        "        return psnr(original, modified)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_ssim(original: np.ndarray, modified: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculate Structural Similarity Index (SSIM).\n",
        "        Values range from 0 to 1, where 1 indicates identical images.\n",
        "        \"\"\"\n",
        "        # Ensure images have the same dimensions\n",
        "        if original.shape != modified.shape:\n",
        "            return 0.0\n",
        "        \n",
        "        return ssim(original, modified, channel_axis=2)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_mse(original: np.ndarray, modified: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculate Mean Squared Error (MSE).\n",
        "        Lower values indicate greater similarity.\n",
        "        \"\"\"\n",
        "        return np.mean((original.astype(float) - modified.astype(float)) ** 2)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_all_metrics(original_path: str, modified_path: str) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Calculate all quality metrics between two images.\n",
        "        \n",
        "        Args:\n",
        "            original_path: Path to original image\n",
        "            modified_path: Path to modified image\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary containing all calculated metrics\n",
        "        \"\"\"\n",
        "        try:\n",
        "            original = np.array(Image.open(original_path).convert('RGB'))\n",
        "            modified = np.array(Image.open(modified_path).convert('RGB'))\n",
        "            \n",
        "            # Resize modified to match original if needed\n",
        "            if original.shape != modified.shape:\n",
        "                modified_img = Image.fromarray(modified).resize(\n",
        "                    (original.shape[1], original.shape[0]), \n",
        "                    Image.Resampling.LANCZOS\n",
        "                )\n",
        "                modified = np.array(modified_img)\n",
        "            \n",
        "            return {\n",
        "                'psnr': ImageMetrics.calculate_psnr(original, modified),\n",
        "                'ssim': ImageMetrics.calculate_ssim(original, modified),\n",
        "                'mse': ImageMetrics.calculate_mse(original, modified)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'psnr': 0.0,\n",
        "                'ssim': 0.0,\n",
        "                'mse': float('inf')\n",
        "            }\n",
        "\n",
        "metrics_calculator = ImageMetrics()\n",
        "\n",
        "print(\"âœ“ Image quality metrics loaded\")\n",
        "print(\"  Available metrics:\")\n",
        "print(\"  - PSNR (Peak Signal-to-Noise Ratio)\")\n",
        "print(\"  - SSIM (Structural Similarity Index)\")\n",
        "print(\"  - MSE (Mean Squared Error)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ”¬ Section 8: Test Watermark Detection\n",
        "\n",
        "### â–¶ï¸ Action Required\n",
        "\n",
        "This section tests watermark detection on all transformed images and generates a comprehensive results file.\n",
        "\n",
        "**What This Does:**\n",
        "1. Scans all transformed images in the output directory\n",
        "2. Attempts to detect watermarks in each image\n",
        "3. Calculates image quality metrics compared to the original\n",
        "4. Saves all results to a CSV file for analysis\n",
        "\n",
        "**Note**: This may take significant time for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Watermark Detection and Results Generation\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "def test_watermark_robustness():\n",
        "    \"\"\"\n",
        "    Test watermark detection on all transformed images and generate results.\n",
        "    \"\"\"\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    # Process each transformation type\n",
        "    transformation_dirs = [d for d in TRANSFORMED_IMAGES_DIR.iterdir() if d.is_dir()]\n",
        "    \n",
        "    print(f\"Testing watermark detection on {len(transformation_dirs)} transformation types...\\n\")\n",
        "    \n",
        "    for transform_dir in tqdm(transformation_dirs, desc=\"Processing transformation types\"):\n",
        "        transform_type = transform_dir.name\n",
        "        \n",
        "        # Get all images in this transformation directory\n",
        "        image_files = sorted([f for f in transform_dir.iterdir() \n",
        "                            if f.suffix.lower() in ['.png', '.jpg', '.jpeg']])\n",
        "        \n",
        "        for image_path in tqdm(image_files, desc=f\"  {transform_type}\", leave=False):\n",
        "            try:\n",
        "                # Extract original image name from transformed filename\n",
        "                # Assumes format: {original_name}_{transformation_details}.ext\n",
        "                parts = image_path.stem.split('_')\n",
        "                original_name = parts[0] if parts else image_path.stem\n",
        "                \n",
        "                # Find corresponding original image\n",
        "                original_image = None\n",
        "                for ext in ['.png', '.jpg', '.jpeg']:\n",
        "                    potential_path = RAW_IMAGES_PATH / f\"{original_name}{ext}\"\n",
        "                    if potential_path.exists():\n",
        "                        original_image = potential_path\n",
        "                        break\n",
        "                \n",
        "                if not original_image:\n",
        "                    print(f\"\\nâš ï¸  Could not find original image for {image_path.name}\")\n",
        "                    continue\n",
        "                \n",
        "                # Detect watermark\n",
        "                detected_bits = detect_watermark(str(image_path))\n",
        "                \n",
        "                # Calculate quality metrics\n",
        "                metrics = metrics_calculator.calculate_all_metrics(\n",
        "                    str(original_image), \n",
        "                    str(image_path)\n",
        "                )\n",
        "                \n",
        "                # Store results\n",
        "                result = {\n",
        "                    'original_image': original_image.name,\n",
        "                    'transformed_image': image_path.name,\n",
        "                    'transformation_type': transform_type,\n",
        "                    'watermark_detected': len(detected_bits) > 0,\n",
        "                    'detected_bits': ''.join(map(str, detected_bits.astype(int).tolist())),\n",
        "                    'num_bits_detected': len(detected_bits),\n",
        "                    'psnr': metrics['psnr'],\n",
        "                    'ssim': metrics['ssim'],\n",
        "                    'mse': metrics['mse']\n",
        "                }\n",
        "                results.append(result)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"\\nâš ï¸  Error processing {image_path.name}: {str(e)}\")\n",
        "                continue\n",
        "    \n",
        "    # Save results to CSV\n",
        "    results_file = RESULTS_DIR / f\"watermark_detection_results_{WATERMARK_METHOD}.csv\"\n",
        "    \n",
        "    if results:\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(results_file, index=False)\n",
        "        \n",
        "        print(f\"\\nâœ“ Testing complete!\")\n",
        "        print(f\"  - Tested {len(results)} images\")\n",
        "        print(f\"  - Results saved to: {results_file}\")\n",
        "        \n",
        "        # Print summary statistics\n",
        "        print(f\"\\nğŸ“Š Summary Statistics:\")\n",
        "        print(f\"  - Total images processed: {len(results)}\")\n",
        "        print(f\"  - Watermarks detected: {sum(r['watermark_detected'] for r in results)}\")\n",
        "        print(f\"  - Detection rate: {sum(r['watermark_detected'] for r in results) / len(results) * 100:.1f}%\")\n",
        "        print(f\"\\n  By transformation type:\")\n",
        "        \n",
        "        for transform_type in df['transformation_type'].unique():\n",
        "            subset = df[df['transformation_type'] == transform_type]\n",
        "            detection_rate = subset['watermark_detected'].sum() / len(subset) * 100\n",
        "            print(f\"    {transform_type:20s}: {detection_rate:5.1f}% detected ({subset['watermark_detected'].sum()}/{len(subset)})\")\n",
        "        \n",
        "        return df\n",
        "    else:\n",
        "        print(\"\\nâš ï¸  No results generated. Please check your configuration and try again.\")\n",
        "        return None\n",
        "\n",
        "# Run the watermark detection tests\n",
        "results_df = test_watermark_robustness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ğŸ“ˆ Section 9: Visualise Results (Optional)\n",
        "\n",
        "This section creates visualisations of the test results to help understand watermark robustness across different transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "# Results Visualisation\n",
        "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "if results_df is not None:\n",
        "    \n",
        "    # Create detection rate by transformation type\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # 1. Detection Rate by Transformation Type\n",
        "    detection_by_type = results_df.groupby('transformation_type')['watermark_detected'].agg(['sum', 'count'])\n",
        "    detection_by_type['rate'] = detection_by_type['sum'] / detection_by_type['count'] * 100\n",
        "    \n",
        "    axes[0, 0].bar(detection_by_type.index, detection_by_type['rate'])\n",
        "    axes[0, 0].set_xlabel('Transformation Type')\n",
        "    axes[0, 0].set_ylabel('Detection Rate (%)')\n",
        "    axes[0, 0].set_title('Watermark Detection Rate by Transformation')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 2. PSNR Distribution\n",
        "    axes[0, 1].hist(results_df['psnr'], bins=30, edgecolor='black')\n",
        "    axes[0, 1].set_xlabel('PSNR (dB)')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].set_title('Distribution of PSNR Values')\n",
        "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 3. SSIM Distribution\n",
        "    axes[1, 0].hist(results_df['ssim'], bins=30, edgecolor='black')\n",
        "    axes[1, 0].set_xlabel('SSIM')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].set_title('Distribution of SSIM Values')\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 4. Detection Rate vs Image Quality\n",
        "    detected = results_df[results_df['watermark_detected'] == True]\n",
        "    not_detected = results_df[results_df['watermark_detected'] == False]\n",
        "    \n",
        "    axes[1, 1].scatter(detected['ssim'], detected['psnr'], alpha=0.5, label='Detected', color='green')\n",
        "    axes[1, 1].scatter(not_detected['ssim'], not_detected['psnr'], alpha=0.5, label='Not Detected', color='red')\n",
        "    axes[1, 1].set_xlabel('SSIM')\n",
        "    axes[1, 1].set_ylabel('PSNR (dB)')\n",
        "    axes[1, 1].set_title('Watermark Detection vs Image Quality')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    visualisation_path = RESULTS_DIR / f\"results_visualisation_{WATERMARK_METHOD}.png\"\n",
        "    plt.savefig(visualisation_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"âœ“ Visualisation saved to: {visualisation_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"âš ï¸  No results available to visualise. Please run the watermark detection tests first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## âœ… Pipeline Complete!\n",
        "\n",
        "### What You've Accomplished\n",
        "\n",
        "1. âœ“ Configured the pipeline for your chosen watermarking method\n",
        "2. âœ“ Applied various transformations to your watermarked images\n",
        "3. âœ“ Tested watermark detection robustness\n",
        "4. âœ“ Generated comprehensive results and visualisations\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Review the results CSV** in the `outputs/{method}/results/` directory\n",
        "- **Analyse the visualisations** to understand which transformations affect watermark detection most\n",
        "- **Test different watermarking methods** by changing `WATERMARK_METHOD` and running the notebook again\n",
        "- **Adjust transformation parameters** in Section 1 to test different scenarios\n",
        "\n",
        "### Need Help?\n",
        "\n",
        "- Refer to the repository README for detailed documentation\n",
        "- Check the configuration sections if you encounter path errors\n",
        "- Review the transformation parameters if you need different test conditions\n",
        "\n",
        "Thank you for using the Watermark Robustness Testing Pipeline!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
