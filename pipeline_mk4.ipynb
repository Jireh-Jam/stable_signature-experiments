{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Watermark Robustness Testing Pipeline\n",
        "\n",
        "## Welcome!\n",
        "\n",
        "This notebook allows you to test how well watermarks survive various image transformations. You don't need to be a technical expert to use this tool.\n",
        "\n",
        "### What Does This Notebook Do?\n",
        "\n",
        "1. **Loads watermarked images** - Brings in images that already have watermarks embedded\n",
        "2. **Applies transformations** - Modifies the images (resize, crop, blur, etc.)\n",
        "3. **Tests watermark detection** - Checks if the watermark can still be found after transformation\n",
        "4. **Generates reports** - Creates CSV files with the results for analysis\n",
        "\n",
        "### Supported Watermarking Methods\n",
        "\n",
        "- **Stable Signature** - Watermarks embedded in latent diffusion models\n",
        "- **Watermark Anything** - General-purpose watermarking system\n",
        "- **TrustMark** - Robust watermarking with quality-factor tuning\n",
        "\n",
        "### How to Use This Notebook\n",
        "\n",
        "**Please read the instructions in each section before running the code.** Do not simply click \"Run All\" - some sections require configuration first.\n",
        "\n",
        "💡 **Tip**: Look for cells marked with ⚙️ (configuration) or ▶️ (action required)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ⚙️ Section 1: Configuration Settings\n",
        "\n",
        "### Important: Please Update These Settings\n",
        "\n",
        "Before running any other cells, you must configure the settings below to match your environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# CONFIGURATION: Choose Your Watermarking Method\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# \n",
        "# Please select ONE watermarking method to test by uncommenting the appropriate line:\n",
        "#\n",
        "# Options:\n",
        "#   - \"Stable_Signature\"      : For images watermarked with Stable Signature\n",
        "#   - \"Watermark_Anything\"    : For images watermarked with Watermark Anything\n",
        "#   - \"TrustMark\"             : For images watermarked with TrustMark\n",
        "#\n",
        "# Note: This notebook processes one method at a time. To test multiple methods,\n",
        "#       run the notebook separately for each one.\n",
        "\n",
        "WATERMARK_METHOD = \"Watermark_Anything\"  # ← Change this to your method\n",
        "# WATERMARK_METHOD = \"TrustMark\"\n",
        "# WATERMARK_METHOD = \"Stable_Signature\"\n",
        "\n",
        "print(f\"✓ Selected watermarking method: {WATERMARK_METHOD}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# CONFIGURATION: Directory Paths\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "#\n",
        "# These paths tell the notebook where to find files and save results.\n",
        "# \n",
        "# If you're using Azure AI:\n",
        "#   - Change 'YourName' to your actual username\n",
        "#   - The default paths should work once you've cloned the repository\n",
        "#\n",
        "# If you're running locally:\n",
        "#   - Modify these paths to match your local directory structure\n",
        "\nimport os\n",
        "\n",
        "# ─── Azure AI Settings ───\n",
        "USER_NAME = 'YourName'  # ← CHANGE THIS to your Azure AI username\n",
        "AZURE_ROOT = '/home/azureuser/cloudfiles/code/Users/'\n",
        "IS_AZURE = os.path.exists(AZURE_ROOT)  # Auto-detect if running on Azure\n",
        "\n",
        "# ─── Path Configuration ───\n",
        "if IS_AZURE:\n",
        "    ROOT_DIR = os.path.join(AZURE_ROOT, USER_NAME)\n",
        "    print(f\"✓ Running on Azure AI with root directory: {ROOT_DIR}\")\n",
        "else:\n",
        "    # Local development - use current working directory\n",
        "    ROOT_DIR = os.getcwd()\n",
        "    print(f\"✓ Running locally with root directory: {ROOT_DIR}\")\n",
        "\n",
        "# Verify the directory exists\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    print(f\"⚠️  WARNING: Root directory does not exist: {ROOT_DIR}\")\n",
        "    print(f\"   Please update USER_NAME or ROOT_DIR paths above.\")\n",
        "else:\n",
        "    print(f\"✓ Root directory confirmed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# CONFIGURATION: Method-Specific Paths\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "#\n",
        "# Each watermarking method requires different files and directories.\n",
        "# These paths are automatically set based on your chosen method.\n",
        "# You may need to adjust these if your repository structure differs.\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "# ─── Repository Structure ───\n",
        "REPO_DIR = Path(ROOT_DIR) / \"ost-embedding-research\"\n",
        "WATERMARK_MODELS_DIR = REPO_DIR / \"watermark_models\"\n",
        "\n",
        "# ─── Method-Specific Configuration ───\n",
        "if WATERMARK_METHOD == \"Watermark_Anything\":\n",
        "    METHOD_DIR = WATERMARK_MODELS_DIR / \"watermark-anything\"\n",
        "    RAW_IMAGES_PATH = METHOD_DIR / \"output\" / \"imgs_w\"\n",
        "    CHECKPOINT_PATH = METHOD_DIR / \"models\" / \"watermark_anything_model.pth\"\n",
        "    OUTPUT_DIR = REPO_DIR / \"outputs\" / \"watermark_anything\"\n",
        "    \n",
        "elif WATERMARK_METHOD == \"TrustMark\":\n",
        "    METHOD_DIR = WATERMARK_MODELS_DIR / \"trustmark\"\n",
        "    RAW_IMAGES_PATH = METHOD_DIR / \"watermarked_images\"\n",
        "    CHECKPOINT_PATH = None  # TrustMark uses built-in models\n",
        "    OUTPUT_DIR = REPO_DIR / \"outputs\" / \"trustmark\"\n",
        "    \n",
        "elif WATERMARK_METHOD == \"Stable_Signature\":\n",
        "    METHOD_DIR = WATERMARK_MODELS_DIR / \"stable-signature\"\n",
        "    RAW_IMAGES_PATH = METHOD_DIR / \"watermarked_images\"\n",
        "    CHECKPOINT_PATH = METHOD_DIR / \"models\" / \"dec_48b_whit.torchscript.pt\"\n",
        "    OUTPUT_DIR = REPO_DIR / \"outputs\" / \"stable_signature\"\n",
        "\n",
        "# ─── Create Output Directories ───\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "TRANSFORMED_IMAGES_DIR = OUTPUT_DIR / \"transformed_images\"\n",
        "RESULTS_DIR = OUTPUT_DIR / \"results\"\n",
        "TRANSFORMED_IMAGES_DIR.mkdir(exist_ok=True)\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(f\"✓ Configuration for {WATERMARK_METHOD}:\")\n",
        "print(f\"  - Method directory: {METHOD_DIR}\")\n",
        "print(f\"  - Raw images: {RAW_IMAGES_PATH}\")\n",
        "print(f\"  - Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"  - Checkpoint: {CHECKPOINT_PATH if CHECKPOINT_PATH else 'Built-in model'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# CONFIGURATION: Processing Options\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "#\n",
        "# Control how many images to process and which transformations to apply.\n",
        "# Start with small numbers for testing, then increase for full analysis.\n",
        "\n",
        "# ─── Number of Images to Process ───\n",
        "# Set to None to process all images, or specify a number for testing\n",
        "MAX_IMAGES_TO_PROCESS = 10  # ← Start with 10 images for testing\n",
        "# MAX_IMAGES_TO_PROCESS = None  # ← Uncomment to process all images\n",
        "\n",
        "# ─── Transformations to Apply ───\n",
        "# Enable or disable specific transformation types\n",
        "APPLY_RESIZE = True          # Resize images to different dimensions\n",
        "APPLY_CROP = True            # Crop images (centre crop with various percentages)\n",
        "APPLY_ROTATION = True        # Rotate images by various angles\n",
        "APPLY_BLUR = True            # Apply Gaussian blur with different strengths\n",
        "APPLY_COMPRESSION = True     # JPEG compression at different quality levels\n",
        "APPLY_NOISE = True           # Add Gaussian noise\n",
        "APPLY_COLOUR_JITTER = True   # Adjust brightness, contrast, saturation\n",
        "\n",
        "# ─── Transformation Parameters ───\n",
        "RESIZE_DIMENSIONS = [(256, 256), (512, 512), (1024, 1024)]\n",
        "CROP_PERCENTAGES = [0.99, 0.90, 0.80, 0.70, 0.60, 0.50]\n",
        "ROTATION_ANGLES = [5, 15, 30, 45, 90, 180]\n",
        "BLUR_KERNEL_SIZES = [3, 11, 21, 51]\n",
        "COMPRESSION_QUALITIES = [95, 85, 75, 50, 25]\n",
        "\n",
        "print(\"✓ Processing configuration set:\")\n",
        "print(f\"  - Maximum images: {MAX_IMAGES_TO_PROCESS if MAX_IMAGES_TO_PROCESS else 'All'}\")\n",
        "print(f\"  - Transformations enabled: \", end=\"\")\n",
        "enabled = [name for name, enabled in [\n",
        "    (\"Resize\", APPLY_RESIZE),\n",
        "    (\"Crop\", APPLY_CROP),\n",
        "    (\"Rotation\", APPLY_ROTATION),\n",
        "    (\"Blur\", APPLY_BLUR),\n",
        "    (\"Compression\", APPLY_COMPRESSION),\n",
        "    (\"Noise\", APPLY_NOISE),\n",
        "    (\"Colour Jitter\", APPLY_COLOUR_JITTER)\n",
        "] if enabled]\n",
        "print(\", \".join(enabled))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 📦 Section 2: Install Dependencies\n",
        "\n",
        "This section installs the required Python packages. These packages enable watermark detection and image processing.\n",
        "\n",
        "**You only need to run this once per environment.** If you've already installed the packages, you can skip this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Install Required Packages\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "#\n",
        "# This cell checks for required packages and installs them if missing.\n",
        "# The installation may take a few minutes on first run.\n",
        "\n",
        "import importlib.util\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "def install_if_missing(package_name, import_name=None):\n",
        "    \"\"\"Install a package if it's not already available.\"\"\"\n",
        "    if import_name is None:\n",
        "        import_name = package_name\n",
        "    \n",
        "    if importlib.util.find_spec(import_name) is None:\n",
        "        print(f\"📥 Installing {package_name}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package_name])\n",
        "        print(f\"✓ {package_name} installed successfully\")\n",
        "    else:\n",
        "        print(f\"✓ {package_name} already installed\")\n",
        "\n",
        "# Core dependencies\n",
        "print(\"Checking and installing dependencies...\\n\")\n",
        "install_if_missing(\"torch\")\n",
        "install_if_missing(\"torchvision\")\n",
        "install_if_missing(\"Pillow\", \"PIL\")\n",
        "install_if_missing(\"numpy\")\n",
        "install_if_missing(\"opencv-python\", \"cv2\")\n",
        "install_if_missing(\"scikit-image\", \"skimage\")\n",
        "install_if_missing(\"pandas\")\n",
        "install_if_missing(\"matplotlib\")\n",
        "install_if_missing(\"tqdm\")\n",
        "\n",
        "# Method-specific dependencies\n",
        "if WATERMARK_METHOD == \"Watermark_Anything\":\n",
        "    install_if_missing(\"timm\")\n",
        "elif WATERMARK_METHOD == \"TrustMark\":\n",
        "    install_if_missing(\"trustmark\")\n",
        "elif WATERMARK_METHOD == \"Stable_Signature\":\n",
        "    install_if_missing(\"omegaconf\")\n",
        "    install_if_missing(\"einops\")\n",
        "\n",
        "print(\"\\n✓ All dependencies are installed and ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🔧 Section 3: Import Libraries and Utilities\n",
        "\n",
        "This section imports all the necessary Python libraries and custom functions for the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Import Required Libraries\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "# Image processing\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import functional as TF\n",
        "\n",
        "# Utilities\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add repository directories to path\n",
        "sys.path.insert(0, str(REPO_DIR))\n",
        "sys.path.insert(0, str(METHOD_DIR))\n",
        "\n",
        "print(\"✓ Libraries imported successfully\")\n",
        "print(f\"✓ Using PyTorch version: {torch.__version__}\")\n",
        "print(f\"✓ CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🔍 Section 4: Load Watermark Detection Model\n",
        "\n",
        "This section loads the appropriate watermark detection model based on your chosen method.\n",
        "\n",
        "Each watermarking method has its own detection system:\n",
        "- **Stable Signature**: Uses a pre-trained decoder model\n",
        "- **Watermark Anything**: Loads a checkpoint and uses message prediction\n",
        "- **TrustMark**: Uses the built-in TrustMark library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Load Watermark Detection Model\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "if WATERMARK_METHOD == \"Watermark_Anything\":\n",
        "    print(\"Loading Watermark Anything model...\")\n",
        "    \n",
        "    # Import method-specific modules\n",
        "    from watermark_anything.data.metrics import msg_predict_inference\n",
        "    from notebooks.inference import load_model_from_checkpoint\n",
        "    \n",
        "    # Load the model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = load_model_from_checkpoint(str(CHECKPOINT_PATH), device=device)\n",
        "    model.eval()\n",
        "    \n",
        "    def detect_watermark(image_path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Detect and return the watermark bits from an image.\n",
        "        \n",
        "        Args:\n",
        "            image_path: Path to the watermarked image\n",
        "            \n",
        "        Returns:\n",
        "            Array of detected watermark bits (0s and 1s)\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = TF.to_tensor(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            detected_bits = msg_predict_inference(model, image_tensor)\n",
        "        \n",
        "        return detected_bits.cpu().numpy()\n",
        "    \n",
        "    print(\"✓ Watermark Anything model loaded successfully\")\n",
        "\n",
        "elif WATERMARK_METHOD == \"TrustMark\":\n",
        "    print(\"Loading TrustMark model...\")\n",
        "    \n",
        "    from trustmark import TrustMark\n",
        "    \n",
        "    # Initialise TrustMark with quality model\n",
        "    trustmark_model = TrustMark(verbose=False, model_type='Q')\n",
        "    \n",
        "    def detect_watermark(image_path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Detect and return the watermark bits from an image using TrustMark.\n",
        "        \n",
        "        Args:\n",
        "            image_path: Path to the watermarked image\n",
        "            \n",
        "        Returns:\n",
        "            Array of detected watermark bits (0s and 1s)\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        detected_bits, _ = trustmark_model.decode(image)\n",
        "        return np.array(detected_bits)\n",
        "    \n",
        "    print(\"✓ TrustMark model loaded successfully\")\n",
        "\n",
        "elif WATERMARK_METHOD == \"Stable_Signature\":\n",
        "    print(\"Loading Stable Signature model...\")\n",
        "    \n",
        "    # Import method-specific modules\n",
        "    from hidden.utils import get_watermarking_mask\n",
        "    \n",
        "    # Load the decoder model\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    decoder = torch.jit.load(str(CHECKPOINT_PATH)).to(device)\n",
        "    decoder.eval()\n",
        "    \n",
        "    def detect_watermark(image_path: str) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Detect and return the watermark bits from an image using Stable Signature.\n",
        "        \n",
        "        Args:\n",
        "            image_path: Path to the watermarked image\n",
        "            \n",
        "        Returns:\n",
        "            Array of detected watermark bits (0s and 1s)\n",
        "        \"\"\"\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        image_tensor = TF.to_tensor(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            detected_bits = decoder(image_tensor)\n",
        "        \n",
        "        return (detected_bits.cpu().numpy() > 0).astype(int).flatten()\n",
        "    \n",
        "    print(\"✓ Stable Signature model loaded successfully\")\n",
        "\n",
        "print(f\"\\n✓ Detection function ready: detect_watermark()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🖼️ Section 5: Image Transformation Functions\n",
        "\n",
        "This section defines functions to apply various transformations to images. Each transformation tests how well the watermark survives different types of image manipulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Image Transformation Functions\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "class ImageTransformations:\n",
        "    \"\"\"Collection of image transformation functions for watermark robustness testing.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def resize(image: Image.Image, width: int, height: int) -> Image.Image:\n",
        "        \"\"\"Resize image to specified dimensions.\"\"\"\n",
        "        return image.resize((width, height), Image.Resampling.LANCZOS)\n",
        "    \n",
        "    @staticmethod\n",
        "    def centre_crop(image: Image.Image, percentage: float) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Crop image from the centre, keeping specified percentage of the original.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            percentage: Percentage of image to keep (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        width, height = image.size\n",
        "        new_width = int(width * percentage)\n",
        "        new_height = int(height * percentage)\n",
        "        \n",
        "        left = (width - new_width) // 2\n",
        "        top = (height - new_height) // 2\n",
        "        right = left + new_width\n",
        "        bottom = top + new_height\n",
        "        \n",
        "        return image.crop((left, top, right, bottom))\n",
        "    \n",
        "    @staticmethod\n",
        "    def rotate(image: Image.Image, angle: float) -> Image.Image:\n",
        "        \"\"\"Rotate image by specified angle (degrees).\"\"\"\n",
        "        return image.rotate(angle, expand=True, fillcolor=(255, 255, 255))\n",
        "    \n",
        "    @staticmethod\n",
        "    def gaussian_blur(image: Image.Image, kernel_size: int) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Apply Gaussian blur to image.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            kernel_size: Size of the Gaussian kernel (must be odd)\n",
        "        \"\"\"\n",
        "        # Convert PIL to numpy for OpenCV\n",
        "        img_array = np.array(image)\n",
        "        blurred = cv2.GaussianBlur(img_array, (kernel_size, kernel_size), 0)\n",
        "        return Image.fromarray(blurred)\n",
        "    \n",
        "    @staticmethod\n",
        "    def jpeg_compression(image: Image.Image, quality: int) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Apply JPEG compression at specified quality level.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            quality: JPEG quality (1-100, higher is better quality)\n",
        "        \"\"\"\n",
        "        from io import BytesIO\n",
        "        buffer = BytesIO()\n",
        "        image.save(buffer, format='JPEG', quality=quality)\n",
        "        buffer.seek(0)\n",
        "        return Image.open(buffer)\n",
        "    \n",
        "    @staticmethod\n",
        "    def add_noise(image: Image.Image, noise_level: float = 0.02) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Add Gaussian noise to image.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            noise_level: Standard deviation of noise (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        img_array = np.array(image).astype(np.float32) / 255.0\n",
        "        noise = np.random.normal(0, noise_level, img_array.shape)\n",
        "        noisy_img = np.clip(img_array + noise, 0, 1)\n",
        "        return Image.fromarray((noisy_img * 255).astype(np.uint8))\n",
        "    \n",
        "    @staticmethod\n",
        "    def colour_jitter(image: Image.Image, brightness: float = 0.2, \n",
        "                     contrast: float = 0.2, saturation: float = 0.2) -> Image.Image:\n",
        "        \"\"\"\n",
        "        Randomly change brightness, contrast, and saturation.\n",
        "        \n",
        "        Args:\n",
        "            image: Input image\n",
        "            brightness: Brightness jitter factor (0.0 to 1.0)\n",
        "            contrast: Contrast jitter factor (0.0 to 1.0)\n",
        "            saturation: Saturation jitter factor (0.0 to 1.0)\n",
        "        \"\"\"\n",
        "        jitter = transforms.ColorJitter(\n",
        "            brightness=brightness,\n",
        "            contrast=contrast,\n",
        "            saturation=saturation\n",
        "        )\n",
        "        return jitter(image)\n",
        "\n",
        "# Create instance for easy access\n",
        "transform = ImageTransformations()\n",
        "\n",
        "print(\"✓ Image transformation functions loaded\")\n",
        "print(\"  Available transformations:\")\n",
        "print(\"  - resize()\")\n",
        "print(\"  - centre_crop()\")\n",
        "print(\"  - rotate()\")\n",
        "print(\"  - gaussian_blur()\")\n",
        "print(\"  - jpeg_compression()\")\n",
        "print(\"  - add_noise()\")\n",
        "print(\"  - colour_jitter()\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🎯 Section 6: Apply Transformations to Images\n",
        "\n",
        "### ▶️ Action Required\n",
        "\n",
        "This section applies all enabled transformations to your watermarked images. \n",
        "\n",
        "**Important Notes:**\n",
        "- This process may take considerable time depending on the number of images and transformations\n",
        "- We recommend testing with a small number of images first (set `MAX_IMAGES_TO_PROCESS = 10` above)\n",
        "- Results are saved to separate subdirectories for each transformation type\n",
        "- You can monitor progress with the progress bars displayed during processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Apply All Transformations\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def apply_transformations_to_dataset():\n",
        "    \"\"\"\n",
        "    Apply all enabled transformations to the dataset of watermarked images.\n",
        "    Creates subdirectories for each transformation type and saves results.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get list of images to process\n",
        "    image_files = sorted([f for f in os.listdir(RAW_IMAGES_PATH) \n",
        "                         if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "    \n",
        "    if MAX_IMAGES_TO_PROCESS:\n",
        "        image_files = image_files[:MAX_IMAGES_TO_PROCESS]\n",
        "    \n",
        "    print(f\"Processing {len(image_files)} images...\\n\")\n",
        "    \n",
        "    # Counter for total transformations\n",
        "    transformation_count = 0\n",
        "    \n",
        "    # Process each image\n",
        "    for image_name in tqdm(image_files, desc=\"Processing images\"):\n",
        "        image_path = os.path.join(RAW_IMAGES_PATH, image_name)\n",
        "        base_name = Path(image_name).stem\n",
        "        \n",
        "        try:\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            \n",
        "            # ─── Resize Transformations ───\n",
        "            if APPLY_RESIZE:\n",
        "                resize_dir = TRANSFORMED_IMAGES_DIR / \"resize\"\n",
        "                resize_dir.mkdir(exist_ok=True)\n",
        "                for width, height in RESIZE_DIMENSIONS:\n",
        "                    resized = transform.resize(image, width, height)\n",
        "                    output_path = resize_dir / f\"{base_name}_resize_{width}x{height}.png\"\n",
        "                    resized.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # ─── Centre Crop Transformations ───\n",
        "            if APPLY_CROP:\n",
        "                crop_dir = TRANSFORMED_IMAGES_DIR / \"crop\"\n",
        "                crop_dir.mkdir(exist_ok=True)\n",
        "                for percentage in CROP_PERCENTAGES:\n",
        "                    cropped = transform.centre_crop(image, percentage)\n",
        "                    output_path = crop_dir / f\"{base_name}_crop_{int(percentage*100)}pct.png\"\n",
        "                    cropped.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # ─── Rotation Transformations ───\n",
        "            if APPLY_ROTATION:\n",
        "                rotation_dir = TRANSFORMED_IMAGES_DIR / \"rotation\"\n",
        "                rotation_dir.mkdir(exist_ok=True)\n",
        "                for angle in ROTATION_ANGLES:\n",
        "                    rotated = transform.rotate(image, angle)\n",
        "                    output_path = rotation_dir / f\"{base_name}_rotate_{angle}deg.png\"\n",
        "                    rotated.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # ─── Blur Transformations ───\n",
        "            if APPLY_BLUR:\n",
        "                blur_dir = TRANSFORMED_IMAGES_DIR / \"blur\"\n",
        "                blur_dir.mkdir(exist_ok=True)\n",
        "                for kernel_size in BLUR_KERNEL_SIZES:\n",
        "                    blurred = transform.gaussian_blur(image, kernel_size)\n",
        "                    output_path = blur_dir / f\"{base_name}_blur_k{kernel_size}.png\"\n",
        "                    blurred.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # ─── Compression Transformations ───\n",
        "            if APPLY_COMPRESSION:\n",
        "                compression_dir = TRANSFORMED_IMAGES_DIR / \"compression\"\n",
        "                compression_dir.mkdir(exist_ok=True)\n",
        "                for quality in COMPRESSION_QUALITIES:\n",
        "                    compressed = transform.jpeg_compression(image, quality)\n",
        "                    output_path = compression_dir / f\"{base_name}_jpeg_q{quality}.jpg\"\n",
        "                    compressed.save(output_path)\n",
        "                    transformation_count += 1\n",
        "            \n",
        "            # ─── Noise Transformations ───\n",
        "            if APPLY_NOISE:\n",
        "                noise_dir = TRANSFORMED_IMAGES_DIR / \"noise\"\n",
        "                noise_dir.mkdir(exist_ok=True)\n",
        "                noisy = transform.add_noise(image)\n",
        "                output_path = noise_dir / f\"{base_name}_noise.png\"\n",
        "                noisy.save(output_path)\n",
        "                transformation_count += 1\n",
        "            \n",
        "            # ─── Colour Jitter Transformations ───\n",
        "            if APPLY_COLOUR_JITTER:\n",
        "                jitter_dir = TRANSFORMED_IMAGES_DIR / \"colour_jitter\"\n",
        "                jitter_dir.mkdir(exist_ok=True)\n",
        "                jittered = transform.colour_jitter(image)\n",
        "                output_path = jitter_dir / f\"{base_name}_jitter.png\"\n",
        "                jittered.save(output_path)\n",
        "                transformation_count += 1\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"\\n⚠️  Error processing {image_name}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    print(f\"\\n✓ Transformation complete!\")\n",
        "    print(f\"  - Processed {len(image_files)} images\")\n",
        "    print(f\"  - Created {transformation_count} transformed images\")\n",
        "    print(f\"  - Results saved to: {TRANSFORMED_IMAGES_DIR}\")\n",
        "\n",
        "# Run the transformation process\n",
        "apply_transformations_to_dataset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 📊 Section 7: Calculate Image Quality Metrics\n",
        "\n",
        "This section defines functions to calculate various image quality metrics. These metrics help quantify how much the transformations have altered the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Image Quality Metrics\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "class ImageMetrics:\n",
        "    \"\"\"Calculate various image quality and similarity metrics.\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_psnr(original: np.ndarray, modified: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculate Peak Signal-to-Noise Ratio (PSNR).\n",
        "        Higher values indicate better quality (less distortion).\n",
        "        \"\"\"\n",
        "        return psnr(original, modified)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_ssim(original: np.ndarray, modified: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculate Structural Similarity Index (SSIM).\n",
        "        Values range from 0 to 1, where 1 indicates identical images.\n",
        "        \"\"\"\n",
        "        # Ensure images have the same dimensions\n",
        "        if original.shape != modified.shape:\n",
        "            return 0.0\n",
        "        \n",
        "        return ssim(original, modified, channel_axis=2)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_mse(original: np.ndarray, modified: np.ndarray) -> float:\n",
        "        \"\"\"\n",
        "        Calculate Mean Squared Error (MSE).\n",
        "        Lower values indicate greater similarity.\n",
        "        \"\"\"\n",
        "        return np.mean((original.astype(float) - modified.astype(float)) ** 2)\n",
        "    \n",
        "    @staticmethod\n",
        "    def calculate_all_metrics(original_path: str, modified_path: str) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Calculate all quality metrics between two images.\n",
        "        \n",
        "        Args:\n",
        "            original_path: Path to original image\n",
        "            modified_path: Path to modified image\n",
        "            \n",
        "        Returns:\n",
        "            Dictionary containing all calculated metrics\n",
        "        \"\"\"\n",
        "        try:\n",
        "            original = np.array(Image.open(original_path).convert('RGB'))\n",
        "            modified = np.array(Image.open(modified_path).convert('RGB'))\n",
        "            \n",
        "            # Resize modified to match original if needed\n",
        "            if original.shape != modified.shape:\n",
        "                modified_img = Image.fromarray(modified).resize(\n",
        "                    (original.shape[1], original.shape[0]), \n",
        "                    Image.Resampling.LANCZOS\n",
        "                )\n",
        "                modified = np.array(modified_img)\n",
        "            \n",
        "            return {\n",
        "                'psnr': ImageMetrics.calculate_psnr(original, modified),\n",
        "                'ssim': ImageMetrics.calculate_ssim(original, modified),\n",
        "                'mse': ImageMetrics.calculate_mse(original, modified)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            return {\n",
        "                'psnr': 0.0,\n",
        "                'ssim': 0.0,\n",
        "                'mse': float('inf')\n",
        "            }\n",
        "\n",
        "metrics_calculator = ImageMetrics()\n",
        "\n",
        "print(\"✓ Image quality metrics loaded\")\n",
        "print(\"  Available metrics:\")\n",
        "print(\"  - PSNR (Peak Signal-to-Noise Ratio)\")\n",
        "print(\"  - SSIM (Structural Similarity Index)\")\n",
        "print(\"  - MSE (Mean Squared Error)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 🔬 Section 8: Test Watermark Detection\n",
        "\n",
        "### ▶️ Action Required\n",
        "\n",
        "This section tests watermark detection on all transformed images and generates a comprehensive results file.\n",
        "\n",
        "**What This Does:**\n",
        "1. Scans all transformed images in the output directory\n",
        "2. Attempts to detect watermarks in each image\n",
        "3. Calculates image quality metrics compared to the original\n",
        "4. Saves all results to a CSV file for analysis\n",
        "\n",
        "**Note**: This may take significant time for large datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Watermark Detection and Results Generation\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "def test_watermark_robustness():\n",
        "    \"\"\"\n",
        "    Test watermark detection on all transformed images and generate results.\n",
        "    \"\"\"\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    # Process each transformation type\n",
        "    transformation_dirs = [d for d in TRANSFORMED_IMAGES_DIR.iterdir() if d.is_dir()]\n",
        "    \n",
        "    print(f\"Testing watermark detection on {len(transformation_dirs)} transformation types...\\n\")\n",
        "    \n",
        "    for transform_dir in tqdm(transformation_dirs, desc=\"Processing transformation types\"):\n",
        "        transform_type = transform_dir.name\n",
        "        \n",
        "        # Get all images in this transformation directory\n",
        "        image_files = sorted([f for f in transform_dir.iterdir() \n",
        "                            if f.suffix.lower() in ['.png', '.jpg', '.jpeg']])\n",
        "        \n",
        "        for image_path in tqdm(image_files, desc=f\"  {transform_type}\", leave=False):\n",
        "            try:\n",
        "                # Extract original image name from transformed filename\n",
        "                # Assumes format: {original_name}_{transformation_details}.ext\n",
        "                parts = image_path.stem.split('_')\n",
        "                original_name = parts[0] if parts else image_path.stem\n",
        "                \n",
        "                # Find corresponding original image\n",
        "                original_image = None\n",
        "                for ext in ['.png', '.jpg', '.jpeg']:\n",
        "                    potential_path = RAW_IMAGES_PATH / f\"{original_name}{ext}\"\n",
        "                    if potential_path.exists():\n",
        "                        original_image = potential_path\n",
        "                        break\n",
        "                \n",
        "                if not original_image:\n",
        "                    print(f\"\\n⚠️  Could not find original image for {image_path.name}\")\n",
        "                    continue\n",
        "                \n",
        "                # Detect watermark\n",
        "                detected_bits = detect_watermark(str(image_path))\n",
        "                \n",
        "                # Calculate quality metrics\n",
        "                metrics = metrics_calculator.calculate_all_metrics(\n",
        "                    str(original_image), \n",
        "                    str(image_path)\n",
        "                )\n",
        "                \n",
        "                # Store results\n",
        "                result = {\n",
        "                    'original_image': original_image.name,\n",
        "                    'transformed_image': image_path.name,\n",
        "                    'transformation_type': transform_type,\n",
        "                    'watermark_detected': len(detected_bits) > 0,\n",
        "                    'detected_bits': ''.join(map(str, detected_bits.astype(int).tolist())),\n",
        "                    'num_bits_detected': len(detected_bits),\n",
        "                    'psnr': metrics['psnr'],\n",
        "                    'ssim': metrics['ssim'],\n",
        "                    'mse': metrics['mse']\n",
        "                }\n",
        "                results.append(result)\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"\\n⚠️  Error processing {image_path.name}: {str(e)}\")\n",
        "                continue\n",
        "    \n",
        "    # Save results to CSV\n",
        "    results_file = RESULTS_DIR / f\"watermark_detection_results_{WATERMARK_METHOD}.csv\"\n",
        "    \n",
        "    if results:\n",
        "        df = pd.DataFrame(results)\n",
        "        df.to_csv(results_file, index=False)\n",
        "        \n",
        "        print(f\"\\n✓ Testing complete!\")\n",
        "        print(f\"  - Tested {len(results)} images\")\n",
        "        print(f\"  - Results saved to: {results_file}\")\n",
        "        \n",
        "        # Print summary statistics\n",
        "        print(f\"\\n📊 Summary Statistics:\")\n",
        "        print(f\"  - Total images processed: {len(results)}\")\n",
        "        print(f\"  - Watermarks detected: {sum(r['watermark_detected'] for r in results)}\")\n",
        "        print(f\"  - Detection rate: {sum(r['watermark_detected'] for r in results) / len(results) * 100:.1f}%\")\n",
        "        print(f\"\\n  By transformation type:\")\n",
        "        \n",
        "        for transform_type in df['transformation_type'].unique():\n",
        "            subset = df[df['transformation_type'] == transform_type]\n",
        "            detection_rate = subset['watermark_detected'].sum() / len(subset) * 100\n",
        "            print(f\"    {transform_type:20s}: {detection_rate:5.1f}% detected ({subset['watermark_detected'].sum()}/{len(subset)})\")\n",
        "        \n",
        "        return df\n",
        "    else:\n",
        "        print(\"\\n⚠️  No results generated. Please check your configuration and try again.\")\n",
        "        return None\n",
        "\n",
        "# Run the watermark detection tests\n",
        "results_df = test_watermark_robustness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 📈 Section 9: Visualise Results (Optional)\n",
        "\n",
        "This section creates visualisations of the test results to help understand watermark robustness across different transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "# Results Visualisation\n",
        "# ═══════════════════════════════════════════════════════════════════════════\n",
        "\n",
        "if results_df is not None:\n",
        "    \n",
        "    # Create detection rate by transformation type\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "    \n",
        "    # 1. Detection Rate by Transformation Type\n",
        "    detection_by_type = results_df.groupby('transformation_type')['watermark_detected'].agg(['sum', 'count'])\n",
        "    detection_by_type['rate'] = detection_by_type['sum'] / detection_by_type['count'] * 100\n",
        "    \n",
        "    axes[0, 0].bar(detection_by_type.index, detection_by_type['rate'])\n",
        "    axes[0, 0].set_xlabel('Transformation Type')\n",
        "    axes[0, 0].set_ylabel('Detection Rate (%)')\n",
        "    axes[0, 0].set_title('Watermark Detection Rate by Transformation')\n",
        "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "    axes[0, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 2. PSNR Distribution\n",
        "    axes[0, 1].hist(results_df['psnr'], bins=30, edgecolor='black')\n",
        "    axes[0, 1].set_xlabel('PSNR (dB)')\n",
        "    axes[0, 1].set_ylabel('Frequency')\n",
        "    axes[0, 1].set_title('Distribution of PSNR Values')\n",
        "    axes[0, 1].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 3. SSIM Distribution\n",
        "    axes[1, 0].hist(results_df['ssim'], bins=30, edgecolor='black')\n",
        "    axes[1, 0].set_xlabel('SSIM')\n",
        "    axes[1, 0].set_ylabel('Frequency')\n",
        "    axes[1, 0].set_title('Distribution of SSIM Values')\n",
        "    axes[1, 0].grid(axis='y', alpha=0.3)\n",
        "    \n",
        "    # 4. Detection Rate vs Image Quality\n",
        "    detected = results_df[results_df['watermark_detected'] == True]\n",
        "    not_detected = results_df[results_df['watermark_detected'] == False]\n",
        "    \n",
        "    axes[1, 1].scatter(detected['ssim'], detected['psnr'], alpha=0.5, label='Detected', color='green')\n",
        "    axes[1, 1].scatter(not_detected['ssim'], not_detected['psnr'], alpha=0.5, label='Not Detected', color='red')\n",
        "    axes[1, 1].set_xlabel('SSIM')\n",
        "    axes[1, 1].set_ylabel('PSNR (dB)')\n",
        "    axes[1, 1].set_title('Watermark Detection vs Image Quality')\n",
        "    axes[1, 1].legend()\n",
        "    axes[1, 1].grid(alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # Save figure\n",
        "    visualisation_path = RESULTS_DIR / f\"results_visualisation_{WATERMARK_METHOD}.png\"\n",
        "    plt.savefig(visualisation_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"✓ Visualisation saved to: {visualisation_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"⚠️  No results available to visualise. Please run the watermark detection tests first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## ✅ Pipeline Complete!\n",
        "\n",
        "### What You've Accomplished\n",
        "\n",
        "1. ✓ Configured the pipeline for your chosen watermarking method\n",
        "2. ✓ Applied various transformations to your watermarked images\n",
        "3. ✓ Tested watermark detection robustness\n",
        "4. ✓ Generated comprehensive results and visualisations\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- **Review the results CSV** in the `outputs/{method}/results/` directory\n",
        "- **Analyse the visualisations** to understand which transformations affect watermark detection most\n",
        "- **Test different watermarking methods** by changing `WATERMARK_METHOD` and running the notebook again\n",
        "- **Adjust transformation parameters** in Section 1 to test different scenarios\n",
        "\n",
        "### Need Help?\n",
        "\n",
        "- Refer to the repository README for detailed documentation\n",
        "- Check the configuration sections if you encounter path errors\n",
        "- Review the transformation parameters if you need different test conditions\n",
        "\n",
        "Thank you for using the Watermark Robustness Testing Pipeline!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
