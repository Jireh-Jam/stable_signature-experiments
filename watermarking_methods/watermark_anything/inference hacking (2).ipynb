{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Copyright (c) Meta Platforms, Inc. and affiliates.\n",
        "All rights reserved.\n",
        "\n",
        "This source code is licensed under the license found in the\n",
        "watermark_anything.NSE file in the root directory of this source tree.\n",
        "\n",
        "The project is CC-BY-NC licensed, as found in the LICENSE file of the github."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Watermark Anything With Localized Messages"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports / Model Loading"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1750801705073
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "['.amlignore',\n '.amlignore.amltmp',\n '.ipynb_aml_checkpoints',\n 'colab.ipynb',\n 'inference hacking.ipynb',\n 'inference hacking.ipynb.amltmp',\n 'inference.ipynb',\n 'inference.ipynb.amltmp',\n 'inference_utils.py',\n '__pycache__']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1750801705218
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # must be run in the root folder\n",
        "%cd .."
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "/mnt/batch/tasks/shared/LS_root/mounts/clusters/deepfake/code/Users/Jireh.Jam/Deepfake-Embedding-Mitigation-Measures/watermark-anything\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1750801705369
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install omegaconf\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting omegaconf\n  Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\nCollecting antlr4-python3-runtime==4.9.*\n  Using cached antlr4_python3_runtime-4.9.3-py3-none-any.whl\nRequirement already satisfied: PyYAML>=5.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from omegaconf) (6.0)\nInstalling collected packages: antlr4-python3-runtime, omegaconf\nSuccessfully installed antlr4-python3-runtime-4.9.3 omegaconf-2.3.0\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1750801707979
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U matplotlib"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: matplotlib in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (3.7.1)\nCollecting matplotlib\n  Using cached matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (9.2 MB)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (3.1.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (23.1)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: importlib-resources>=3.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (5.12.0)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: numpy<2,>=1.20 in /home/azureuser/.local/lib/python3.8/site-packages (from matplotlib) (1.24.4)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (4.40.0)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (1.1.0)\nRequirement already satisfied: pillow>=6.2.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: zipp>=3.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\nRequirement already satisfied: six>=1.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\nInstalling collected packages: matplotlib\n  Attempting uninstall: matplotlib\n    Found existing installation: matplotlib 3.7.1\n    Uninstalling matplotlib-3.7.1:\n      Successfully uninstalled matplotlib-3.7.1\nSuccessfully installed matplotlib-3.7.5\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1750801714091
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikit-image"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting scikit-image\n  Downloading scikit_image-0.21.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/13.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: packaging>=21 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-image) (23.1)\nCollecting imageio>=2.27\n  Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.4/315.4 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting PyWavelets>=1.1.1\n  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hCollecting lazy_loader>=0.2\n  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\nRequirement already satisfied: pillow>=9.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-image) (9.5.0)\nRequirement already satisfied: numpy>=1.21.1 in /home/azureuser/.local/lib/python3.8/site-packages (from scikit-image) (1.24.4)\nCollecting networkx>=2.8\n  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting tifffile>=2022.8.12\n  Downloading tifffile-2023.7.10-py3-none-any.whl (220 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: scipy>=1.8 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-image) (1.10.1)\nInstalling collected packages: tifffile, PyWavelets, networkx, lazy_loader, imageio, scikit-image\nSuccessfully installed PyWavelets-1.4.1 imageio-2.35.1 lazy_loader-0.4 networkx-3.1 scikit-image-0.21.0 tifffile-2023.7.10\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1750801720921
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: scikit-learn in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (1.2.2)\nCollecting scikit-learn\n  Using cached scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\nRequirement already satisfied: scipy>=1.5.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\nRequirement already satisfied: joblib>=1.1.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\nRequirement already satisfied: numpy<2.0,>=1.17.3 in /home/azureuser/.local/lib/python3.8/site-packages (from scikit-learn) (1.24.4)\nInstalling collected packages: scikit-learn\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\nSuccessfully installed scikit-learn-1.3.2\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1750801725422
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "pip install einops"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "print(sys.version)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "3.8.5 (default, Sep  4 2020, 07:30:14) \n[GCC 7.3.0]\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1750801727645
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%pip install omegaconf==2.3.0\n",
        "%pip install einops==0.8.0\n",
        "%pip install pycocotools==2.0.8\n",
        "%pip install timm==1.0.11\n",
        "%pip install opencv-python==4.10.0.84\n",
        "%pip install lpips==0.1.4\n",
        "%pip install scikit-image==0.24.0\n",
        "%pip install scikit-learn==1.5.2"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: omegaconf==2.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (2.3.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from omegaconf==2.3.0) (4.9.3)\nRequirement already satisfied: PyYAML>=5.1.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from omegaconf==2.3.0) (6.0)\nNote: you may need to restart the kernel to use updated packages.\nCollecting einops==0.8.0\n  Using cached einops-0.8.0-py3-none-any.whl (43 kB)\nInstalling collected packages: einops\n  Attempting uninstall: einops\n    Found existing installation: einops 0.8.1\n    Uninstalling einops-0.8.1:\n      Successfully uninstalled einops-0.8.1\nSuccessfully installed einops-0.8.0\nNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: Ignored the following versions that require a different python version: 2.0.10 Requires-Python >=3.9; 2.0.8 Requires-Python >=3.9; 2.0.9 Requires-Python >=3.9\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement pycocotools==2.0.8 (from versions: 2.0.0, 2.0.1, 2.0.2a1, 2.0.2, 2.0.3, 2.0.4, 2.0.5, 2.0.6, 2.0.7)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for pycocotools==2.0.8\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\nCollecting timm==1.0.11\n  Using cached timm-1.0.11-py3-none-any.whl (2.3 MB)\nCollecting safetensors\n  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\nRequirement already satisfied: pyyaml in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from timm==1.0.11) (6.0)\nRequirement already satisfied: torch in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from timm==1.0.11) (1.12.0)\nRequirement already satisfied: torchvision in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from timm==1.0.11) (0.13.0)\nCollecting huggingface_hub\n  Using cached huggingface_hub-0.33.0-py3-none-any.whl (514 kB)\nCollecting fsspec>=2023.5.0\n  Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\nCollecting filelock\n  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\nRequirement already satisfied: packaging>=20.9 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface_hub->timm==1.0.11) (23.1)\nRequirement already satisfied: tqdm>=4.42.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface_hub->timm==1.0.11) (4.65.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface_hub->timm==1.0.11) (4.6.3)\nCollecting hf-xet<2.0.0,>=1.1.2\n  Using cached hf_xet-1.1.5-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from huggingface_hub->timm==1.0.11) (2.31.0)\nRequirement already satisfied: numpy in /home/azureuser/.local/lib/python3.8/site-packages (from torchvision->timm==1.0.11) (1.24.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from torchvision->timm==1.0.11) (9.5.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface_hub->timm==1.0.11) (3.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface_hub->timm==1.0.11) (2023.5.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface_hub->timm==1.0.11) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->huggingface_hub->timm==1.0.11) (3.4)\nInstalling collected packages: safetensors, hf-xet, fsspec, filelock, huggingface_hub, timm\nSuccessfully installed filelock-3.16.1 fsspec-2025.3.0 hf-xet-1.1.5 huggingface_hub-0.33.0 safetensors-0.5.3 timm-1.0.11\nNote: you may need to restart the kernel to use updated packages.\nCollecting opencv-python==4.10.0.84\n  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\nRequirement already satisfied: numpy>=1.17.3 in /home/azureuser/.local/lib/python3.8/site-packages (from opencv-python==4.10.0.84) (1.24.4)\nInstalling collected packages: opencv-python\n  Attempting uninstall: opencv-python\n    Found existing installation: opencv-python 4.9.0.80\n    Uninstalling opencv-python-4.9.0.80:\n      Successfully uninstalled opencv-python-4.9.0.80\nSuccessfully installed opencv-python-4.10.0.84\nNote: you may need to restart the kernel to use updated packages.\nCollecting lpips==0.1.4\n  Using cached lpips-0.1.4-py3-none-any.whl (53 kB)\nRequirement already satisfied: scipy>=1.0.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from lpips==0.1.4) (1.10.1)\nRequirement already satisfied: tqdm>=4.28.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from lpips==0.1.4) (4.65.0)\nRequirement already satisfied: numpy>=1.14.3 in /home/azureuser/.local/lib/python3.8/site-packages (from lpips==0.1.4) (1.24.4)\nRequirement already satisfied: torch>=0.4.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from lpips==0.1.4) (1.12.0)\nRequirement already satisfied: torchvision>=0.2.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from lpips==0.1.4) (0.13.0)\nRequirement already satisfied: typing_extensions in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from torch>=0.4.0->lpips==0.1.4) (4.6.3)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from torchvision>=0.2.1->lpips==0.1.4) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from torchvision>=0.2.1->lpips==0.1.4) (9.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->torchvision>=0.2.1->lpips==0.1.4) (2023.5.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->torchvision>=0.2.1->lpips==0.1.4) (3.1.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->torchvision>=0.2.1->lpips==0.1.4) (1.26.16)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->torchvision>=0.2.1->lpips==0.1.4) (3.4)\nInstalling collected packages: lpips\nSuccessfully installed lpips-0.1.4\nNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: Ignored the following versions that require a different python version: 0.22.0 Requires-Python >=3.9; 0.22.0rc1 Requires-Python >=3.9; 0.23.0 Requires-Python >=3.10; 0.23.0rc0 Requires-Python >=3.10; 0.23.0rc2 Requires-Python >=3.10; 0.23.1 Requires-Python >=3.10; 0.23.2 Requires-Python >=3.10; 0.23.2rc1 Requires-Python >=3.10; 0.24.0 Requires-Python >=3.9; 0.24.0rc1 Requires-Python >=3.9; 0.25.0 Requires-Python >=3.10; 0.25.0rc0 Requires-Python >=3.10; 0.25.0rc1 Requires-Python >=3.10; 0.25.0rc2 Requires-Python >=3.10; 0.25.1 Requires-Python >=3.10; 0.25.2 Requires-Python >=3.10; 0.25.2rc0 Requires-Python >=3.10\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-image==0.24.0 (from versions: 0.7.2, 0.8.0, 0.8.1, 0.8.2, 0.9.0, 0.9.1, 0.9.3, 0.10.0, 0.10.1, 0.11.2, 0.11.3, 0.12.0, 0.12.1, 0.12.2, 0.12.3, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.14.2, 0.14.3, 0.14.5, 0.15.0, 0.16.2, 0.17.1, 0.17.2, 0.18.0, 0.18.1, 0.18.2, 0.18.3, 0.19.0rc0, 0.19.0, 0.19.1, 0.19.2, 0.19.3, 0.20.0.dev0, 0.20.0rc2, 0.20.0rc3, 0.20.0rc4, 0.20.0rc5, 0.20.0rc6, 0.20.0rc7, 0.20.0rc8, 0.20.0, 0.21.0rc0, 0.21.0rc1, 0.21.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for scikit-image==0.24.0\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n\u001b[31mERROR: Ignored the following versions that require a different python version: 1.4.0 Requires-Python >=3.9; 1.4.0rc1 Requires-Python >=3.9; 1.4.1.post1 Requires-Python >=3.9; 1.4.2 Requires-Python >=3.9; 1.5.0 Requires-Python >=3.9; 1.5.0rc1 Requires-Python >=3.9; 1.5.1 Requires-Python >=3.9; 1.5.2 Requires-Python >=3.9; 1.6.0 Requires-Python >=3.9; 1.6.0rc1 Requires-Python >=3.9; 1.6.1 Requires-Python >=3.9; 1.7.0 Requires-Python >=3.10; 1.7.0rc1 Requires-Python >=3.10\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement scikit-learn==1.5.2 (from versions: 0.9, 0.10, 0.11, 0.12, 0.12.1, 0.13, 0.13.1, 0.14, 0.14.1, 0.15.0, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.17, 0.17.1, 0.18, 0.18.1, 0.18.2, 0.19.0, 0.19.1, 0.19.2, 0.20.0, 0.20.1, 0.20.2, 0.20.3, 0.20.4, 0.21.1, 0.21.2, 0.21.3, 0.22, 0.22.1, 0.22.2, 0.22.2.post1, 0.23.0, 0.23.1, 0.23.2, 0.24.0, 0.24.1, 0.24.2, 1.0, 1.0.1, 1.0.2, 1.1.0, 1.1.1, 1.1.2, 1.1.3, 1.2.0rc1, 1.2.0, 1.2.1, 1.2.2, 1.3.0rc1, 1.3.0, 1.3.1, 1.3.2)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for scikit-learn==1.5.2\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from watermark_anything.data.metrics import msg_predict_inference\n",
        "from notebooks.inference_utils import (\n",
        "    load_model_from_checkpoint, \n",
        "    default_transform, \n",
        "    create_random_mask, \n",
        "    unnormalize_img,\n",
        "    plot_outputs,\n",
        "    msg2str\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# to load images\n",
        "def load_img(path):\n",
        "    img = Image.open(path).convert(\"RGB\")\n",
        "    img = default_transform(img).unsqueeze(0).to(device)\n",
        "    return img\n",
        "\n",
        "# Load the model from the specified checkpoint\n",
        "exp_dir = \"checkpoints\"\n",
        "json_path = os.path.join(exp_dir, \"params.json\")\n",
        "ckpt_path = os.path.join(exp_dir, 'wam_mit.pth') \n",
        "wam = load_model_from_checkpoint(json_path, ckpt_path).to(device).eval()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "/anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'type' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save_image\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwatermark_anything\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m msg_predict_inference\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnotebooks\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minference_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     load_model_from_checkpoint, \n\u001b[1;32m     12\u001b[0m     default_transform, \n\u001b[1;32m     13\u001b[0m     create_random_mask, \n\u001b[1;32m     14\u001b[0m     unnormalize_img,\n\u001b[1;32m     15\u001b[0m     plot_outputs,\n\u001b[1;32m     16\u001b[0m     msg2str\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# to load images\u001b[39;00m\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/deepfake/code/Users/Jireh.Jam/Deepfake-Embedding-Mitigation-Measures/watermark-anything/notebooks/inference_utils.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwatermark_anything\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Wam, build_embedder, build_extractor\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwatermark_anything\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmentation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmenter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Augmenter\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwatermark_anything\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m default_transform, normalize_img, unnormalize_img\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/deepfake/code/Users/Jireh.Jam/Deepfake-Embedding-Mitigation-Measures/watermark-anything/watermark_anything/models/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# All rights reserved.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the license found in the\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embedder, VAEEmbedder, build_embedder\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextractor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Extractor, SegmentationExtractor, build_extractor\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Wam\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/deepfake/code/Users/Jireh.Jam/Deepfake-Embedding-Mitigation-Measures/watermark-anything/watermark_anything/models/embedder.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvae\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m VAEEncoder, VAEDecoder\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmsg_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MsgProcessor\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEmbedder\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/deepfake/code/Users/Jireh.Jam/Deepfake-Embedding-Mitigation-Measures/watermark-anything/watermark_anything/modules/vae.py:176\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m LinAttnBlock(in_channels)\n\u001b[0;32m--> 176\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVAEEncoder\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    179\u001b[0m         \u001b[38;5;241m*\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mignore_kwargs\n\u001b[1;32m    194\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/deepfake/code/Users/Jireh.Jam/Deepfake-Embedding-Mitigation-Measures/watermark-anything/watermark_anything/modules/vae.py:182\u001b[0m, in \u001b[0;36mVAEEncoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mVAEEncoder\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m    179\u001b[0m         \u001b[38;5;241m*\u001b[39m, \n\u001b[1;32m    180\u001b[0m         ch: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m    181\u001b[0m         out_ch: \u001b[38;5;28mint\u001b[39m, \n\u001b[0;32m--> 182\u001b[0m         ch_mult: \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m8\u001b[39m), \n\u001b[1;32m    183\u001b[0m         num_res_blocks: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m    184\u001b[0m         attn_resolutions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], \n\u001b[1;32m    185\u001b[0m         dropout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m,\n\u001b[1;32m    186\u001b[0m         resamp_with_conv: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    187\u001b[0m         in_channels: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m    188\u001b[0m         resolution: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m    189\u001b[0m         z_channels: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m    190\u001b[0m         double_z: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m    191\u001b[0m         use_linear_attn: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m    192\u001b[0m         attn_type: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvanilla\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[1;32m    193\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mignore_kwargs\n\u001b[1;32m    194\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m use_linear_attn: \n",
            "\u001b[0;31mTypeError\u001b[0m: 'type' object is not subscriptable"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1750801759395
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###ADDED BY DF (From instructions in GitHub readme)\n",
        "from huggingface_hub import hf_hub_download\n",
        "ckpt_path = hf_hub_download(\n",
        "    repo_id=\"facebook/watermark-anything\",\n",
        "    filename=\"checkpoint.pth\"\n",
        ")\n",
        "\n",
        "wam = load_model_from_checkpoint(json_path, ckpt_path).to(device).eval()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1750801759595
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seed \n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# Parameters\n",
        "img_dir = \"/home/azureuser/cloudfiles/code/Users/David.Fletcher/embedding_data/raw_watermarked_images\"  # Directory containing the original images\n",
        "num_imgs = 700  # Number of images to watermark from the folder\n",
        "proportion_masked = 0.8  # Proportion of the image to be watermarked (0.5 means 50% of the image)\n",
        "\n",
        "# create output folder\n",
        "output_dir = \"outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1750801759610
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One localized watermark per image"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# define a 32-bit message to be embedded into the images\n",
        "wm_msg = wam.get_random_msg(1)  # [1, 32]\n",
        "print(f\"Original message to hide: {msg2str(wm_msg[0])}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Define valid image extensions\n",
        "valid_exts = ('.png', '.jpg', '.jpeg', '.bmp')\n",
        "\n",
        "# Get all valid image files in the directory\n",
        "valid_files = [f for f in os.listdir(img_dir) if f.lower().endswith(valid_exts)]\n",
        "for img_ in valid_files[:num_imgs]:\n",
        "    print(f\"Processing image: {img_}\")\n",
        "    # Load and preprocess the image\n",
        "    img_pt = load_img(os.path.join(img_dir, img_))  # [1, 3, H, W]\n",
        "    \n",
        "    # Embed the watermark message into the image\n",
        "    outputs = wam.embed(img_pt, wm_msg)\n",
        "\n",
        "    # Create a random mask to watermark only a part of the image\n",
        "    mask = create_random_mask(img_pt, num_masks=1, mask_percentage=proportion_masked)  # [1, 1, H, W]\n",
        "    img_w = outputs['imgs_w'] * mask + img_pt * (1 - mask)  # [1, 3, H, W]\n",
        "\n",
        "    # Detect the watermark in the watermarked image\n",
        "    preds = wam.detect(img_w)[\"preds\"]  # [1, 33, 256, 256]\n",
        "    mask_preds = F.sigmoid(preds[:, 0, :, :])  # [1, 256, 256], predicted mask\n",
        "    bit_preds = preds[:, 1:, :, :]  # [1, 32, 256, 256], predicted bits\n",
        "    \n",
        "    # Predict the embedded message and calculate bit accuracy\n",
        "    pred_message = msg_predict_inference(bit_preds, mask_preds).cpu().float()  # [1, 32]\n",
        "    bit_acc = (pred_message == wm_msg).float().mean().item()\n",
        "\n",
        "    # Save the watermarked image and the detection mask\n",
        "    mask_preds_res = F.interpolate(mask_preds.unsqueeze(1), size=(img_pt.shape[-2], img_pt.shape[-1]), mode=\"bilinear\", align_corners=False)  # [1, 1, H, W]\n",
        "    save_image(unnormalize_img(img_w), f\"{output_dir}/{img_}_wm.png\")\n",
        "    save_image(mask_preds_res, f\"{output_dir}/{img_}_pred.png\")\n",
        "    save_image(mask, f\"{output_dir}/{img_}_target.png\")\n",
        "\n",
        "\n",
        "    \n",
        "    plot_outputs(img_pt.detach(), img_w.detach(), mask.detach(), mask_preds_res.detach(), labels = None, centroids = None)\n",
        "    \n",
        "    # Print the predicted message and bit accuracy for each image\n",
        "    print(f\"Predicted message for image {img_}: {msg2str(pred_message[0])}\")\n",
        "    print(f\"Bit accuracy for image {img_}: {bit_acc:.2f}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1750801759628
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.functional import to_tensor\n",
        "\n",
        "# List all files in the output directory that end with '_wm.png'\n",
        "wm_files = [f for f in os.listdir(output_dir) if f.endswith('_wm.png')]\n",
        "\n",
        "for wm_file in wm_files:\n",
        "    wm_path = os.path.join(output_dir, wm_file)\n",
        "    # Load the watermarked image and preprocess\n",
        "    img = Image.open(wm_path).convert(\"RGB\")\n",
        "    img_tensor = default_transform(img).unsqueeze(0).to(device)\n",
        "    # Detect watermark\n",
        "    preds = wam.detect(img_tensor)[\"preds\"]\n",
        "    mask_preds = torch.sigmoid(preds[:, 0, :, :])\n",
        "    bit_preds = preds[:, 1:, :, :]\n",
        "    # Predict message\n",
        "    pred_message = msg_predict_inference(bit_preds, mask_preds).cpu().float()\n",
        "    # Print result\n",
        "    print(f\"{wm_file}: {msg2str(pred_message[0])}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1750801759648
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Two localized watermarks per image"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from notebooks.inference_utils import multiwm_dbscan\n",
        "\n",
        "# DBSCAN parameters for detection\n",
        "epsilon = 1 # min distance between decoded messages in a cluster\n",
        "min_samples = 700 # min number of pixels in a 256x256 image to form a cluster\n",
        "\n",
        "# multiple 32 bit message to hide (could be more than 2; does not have to be 1 minus the other)\n",
        "wm_msgs = wam.get_random_msg(2)\n",
        "print(\"Original messages: \", [msg2str(msg) for msg in wm_msgs])\n",
        "proportion_masked = 0.1 # max proportion per watermark, randomly placed\n",
        "\n",
        "\n",
        "# Define valid image extensions\n",
        "valid_exts = ('.png', '.jpg', '.jpeg', '.bmp')\n",
        "\n",
        "# Get all valid image files in the directory\n",
        "valid_files = [f for f in os.listdir(img_dir) if f.lower().endswith(valid_exts)]\n",
        "for img_ in valid_files[:num_imgs]:\n",
        "    print(f\"Processing image: {img_}\")\n",
        "    \n",
        "    # Load and preprocess the image\n",
        "    img_pt = load_img(os.path.join(img_dir, img_))  # [1, 3, H, W]\n",
        "    \n",
        "    # Mask to use. 1 values correspond to pixels where the watermark will be placed.\n",
        "    masks = create_random_mask(img_pt, num_masks=len(wm_msgs), mask_percentage=proportion_masked)  # create one random mask per message\n",
        "    multi_wm_img = img_pt.clone()\n",
        "    for ii in range(len(wm_msgs)):\n",
        "        wm_msg, mask = wm_msgs[ii].unsqueeze(0), masks[ii]\n",
        "        outputs = wam.embed(img_pt, wm_msg) \n",
        "        multi_wm_img = outputs['imgs_w'] * mask + multi_wm_img * (1 - mask)  # [1, 3, H, W]\n",
        "\n",
        "    # Detect the watermark in the multi-watermarked image\n",
        "    preds = wam.detect(multi_wm_img)[\"preds\"]  # [1, 33, 256, 256]\n",
        "    mask_preds = F.sigmoid(preds[:, 0, :, :])  # [1, 256, 256], predicted mask\n",
        "    mask_preds_res = F.interpolate(mask_preds.unsqueeze(1), size=(img_pt.shape[-2], img_pt.shape[-1]), mode=\"bilinear\", align_corners=False)  # [1, 1, H, W]\n",
        "    bit_preds = preds[:, 1:, :, :]  # [1, 32, 256, 256], predicted bits\n",
        "\n",
        "    centroids, positions = multiwm_dbscan(bit_preds, mask_preds, epsilon = epsilon, min_samples = min_samples)\n",
        "    centroids_pt = torch.stack(list(centroids.values()))\n",
        "    plot_outputs(img_pt.detach(), multi_wm_img.detach(), masks.sum(0).detach(), (mask_preds_res>0.5).float().detach(), labels = positions, centroids = centroids)\n",
        "    # positions has the cluster number at each pixel. can be upsaled back to the original size.\n",
        "\n",
        "    print(f\"number messages found in image {img_}: {len(centroids)}\")\n",
        "    for centroid in centroids_pt:\n",
        "        print(f\"found centroid: {msg2str(centroid)}\")\n",
        "        bit_acc = (centroid == wm_msgs).float().mean(dim=1)\n",
        "        # get message with maximum bit accuracy\n",
        "        bit_acc, idx = bit_acc.max(dim=0)\n",
        "        hamming = int(torch.sum(centroid != wm_msgs[idx]).item())\n",
        "        print(f\"bit accuracy: {bit_acc.item()} - hamming distance: {hamming}/{len(wm_msgs[0])}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1750801759663
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With segmentation masks"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from notebooks.inference_utils import multiwm_dbscan\n",
        "\n",
        "# DBSCAN parameters for detection\n",
        "epsilon = 1 # min distance between decoded messages in a cluster\n",
        "min_samples = 500 # min number of pixels in a 256x256 image to form a cluster\n",
        "\n",
        "# multiple 32 bit message to hide (could be more than 2; does not have to be 1 minus the other)\n",
        "wm_msgs = wam.get_random_msg(2)\n",
        "print(\"Original messages: \", [msg2str(msg) for msg in wm_msgs])\n",
        "\n",
        "# Parameters\n",
        "img_dir2 = \"assets/images\"  # Directory containing the original images\n",
        "# load image\n",
        "img_pt = load_img(os.path.join(img_dir2, \"ducks.jpg\"))\n",
        "\n",
        "# load background\n",
        "img_pt_background = load_img(os.path.join(img_dir2, \"seabackground.jpg\"))\n",
        "img_pt_background = F.interpolate(img_pt_background, size=(img_pt.shape[-2], img_pt.shape[-1]), mode=\"bilinear\", align_corners=False)\n",
        "\n",
        "multi_wm_img = img_pt_background.clone()\n",
        "\n",
        "# Creates mask to use. `1` where the watermark will be placed, `0` elsewhere.\n",
        "masks = []\n",
        "for duck_nb in [1, 2]:\n",
        "    mask_path = f'assets/masks/ducks_{duck_nb}.jpg'\n",
        "    mask = Image.open(mask_path).convert('L')  # Convert to grayscale\n",
        "    target_shape = (img_pt.shape[-1], img_pt.shape[-2]) \n",
        "    mask = mask.resize(target_shape, Image.NEAREST)\n",
        "    mask_array = np.array(mask) \n",
        "    mask_array = (mask_array > 128).astype(np.float32) \n",
        "    masks.append(mask_array)\n",
        "masks = torch.tensor(np.array(masks)).to(device)\n",
        "\n",
        "for ii in range(len(wm_msgs)):\n",
        "    wm_msg, mask = wm_msgs[ii].unsqueeze(0), masks[ii]\n",
        "    outputs = wam.embed(img_pt, wm_msg)\n",
        "    multi_wm_img = outputs['imgs_w'] * mask + multi_wm_img * (1 - mask)  # [1, 3, H, W]\n",
        "\n",
        "# Detect the watermark in the multi-watermarked image\n",
        "preds = wam.detect(multi_wm_img)[\"preds\"]  # [1, 33, 256, 256]\n",
        "mask_preds = F.sigmoid(preds[:, 0, :, :])  # [1, 256, 256], predicted mask\n",
        "mask_preds_res = F.interpolate(mask_preds.unsqueeze(1), size=(img_pt.shape[-2], img_pt.shape[-1]), mode=\"nearest\")  # [1, 1, H, W]\n",
        "bit_preds = preds[:, 1:, :, :]  # [1, 32, 256, 256], predicted bits\n",
        "\n",
        "centroids, positions = multiwm_dbscan(bit_preds, mask_preds, epsilon = epsilon, min_samples = min_samples)\n",
        "centroids_pt = torch.stack(list(centroids.values()))\n",
        "plot_outputs(img_pt.detach(), multi_wm_img.detach(), masks.sum(0).detach(), (mask_preds_res>0.5).float().detach(), labels = positions, centroids = centroids)\n",
        "# positions has the cluster number at each pixel. can be upsaled back to the original size.\n",
        "\n",
        "print(f\"number messages found in image {img_}: {len(centroids)}\")\n",
        "for centroid in centroids_pt:\n",
        "    print(f\"found centroid: {msg2str(centroid)}\")\n",
        "    bit_acc = (centroid == wm_msgs).float().mean(dim=1)\n",
        "    # get message with maximum bit accuracy\n",
        "    bit_acc, idx = bit_acc.max(dim=0)\n",
        "    hamming = int(torch.sum(centroid != wm_msgs[idx]).item())\n",
        "    print(f\"bit accuracy: {bit_acc.item()} - hamming distance: {hamming}/{len(wm_msgs[0])}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1750801759684
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "py38_pt_tf",
      "language": "python",
      "display_name": "py38_PT_TF"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "kernel_info": {
      "name": "py38_pt_tf"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}