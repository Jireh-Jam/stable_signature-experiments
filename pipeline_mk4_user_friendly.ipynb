{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Watermark Testing Pipeline - User Guide\n",
    "\n",
    "**Welcome!** This notebook helps you test how well digital watermarks survive various image transformations.\n",
    "\n",
    "## What does this do?\n",
    "This tool will:\n",
    "1. üì• **Download** sample images from storage\n",
    "2.  **Add watermarks** to protect the images\n",
    "3.  **Transform** the images (blur, crop, brighten, etc.)\n",
    "4.  **Check** if watermarks are still detectable\n",
    "5.  **Generate reports** showing the results\n",
    "\n",
    "## Before you start\n",
    "-  **Time needed**: 15-30 minutes\n",
    "- üíæ **Storage**: About 500MB of disk space\n",
    "-  **Environment**: This works best in Azure AI Studio\n",
    "\n",
    "## How to use this notebook\n",
    "1. **Read each section carefully** before running it\n",
    "2. **Update the settings** in Section 1 with your details\n",
    "3. **Run cells one by one** using Shift+Enter\n",
    "4. **Don't run everything at once** - some sections are optional\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 1: Initial Setup\n",
    "\n",
    "**What this does:** Sets up the basic configuration and file paths for your experiment.\n",
    "\n",
    "** Important:** You must update the `user_name` below with your actual username!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß CONFIGURATION - Please update these settings\n",
    "\n",
    "# Your username (MUST CHANGE THIS!)\n",
    "user_name = 'David.Fletcher'  #  Replace with your actual username\n",
    "\n",
    "# Choose which watermarking method to test\n",
    "# Options: \"Stable_Signature\", \"TrustMark\", \"Watermark_Anything\"\n",
    "watermark_method = \"Stable_Signature\"  # üìù Most reliable option\n",
    "\n",
    "# How many images to process (start small for testing)\n",
    "max_images_to_process = 5  #  Increase this for larger experiments\n",
    "\n",
    "# File system setup (usually works as-is in Azure AI)\n",
    "azure_root_dir = '/home/azureuser/cloudfiles/code/Users/'\n",
    "home_directory = azure_root_dir + user_name + '/'\n",
    "\n",
    "print(f\" Configuration set for user: {user_name}\")\n",
    "print(f\"üîß Using watermark method: {watermark_method}\")\n",
    "print(f\"üìÅ Home directory: {home_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 2: Install Required Packages\n",
    "\n",
    "**What this does:** Installs the software packages needed for watermarking and image processing.\n",
    "\n",
    "**Note:** This may take a few minutes the first time you run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import essential libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # Hide technical warnings\n",
    "\n",
    "print(\" Basic packages loaded successfully!\")\n",
    "\n",
    "# Check if we need to install additional packages\n",
    "try:\n",
    "    import torch\n",
    "    print(\"üî• PyTorch is available\")\n",
    "except ImportError:\n",
    "    print(\" PyTorch not found - you may need to install it\")\n",
    "\n",
    "# Set up directories\n",
    "os.makedirs(home_directory + 'embedding_data', exist_ok=True)\n",
    "os.makedirs(home_directory + 'embedding_data/raw_images', exist_ok=True)\n",
    "os.makedirs(home_directory + 'embedding_data/watermarked_images', exist_ok=True)\n",
    "os.makedirs(home_directory + 'embedding_data/transformed_images', exist_ok=True)\n",
    "os.makedirs(home_directory + 'embedding_data/results', exist_ok=True)\n",
    "\n",
    "print(\"üìÅ Directory structure created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 3: Download Sample Images (Optional)\n",
    "\n",
    "**What this does:** Downloads test images from Azure Blob Storage.\n",
    "\n",
    "**When to run:** Only if you need fresh test images. Skip this if you already have images in your folder.\n",
    "\n",
    "** Note:** This requires Azure credentials and may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Set this to True only if you want to download new images\n",
    "DOWNLOAD_IMAGES = False  # Change to True if you need to download images\n",
    "\n",
    "if DOWNLOAD_IMAGES:\n",
    "    print(\" Starting image download...\")\n",
    "    \n",
    "    # Azure Blob Storage configuration\n",
    "    try:\n",
    "        from azure.storage.blob import BlobServiceClient\n",
    "        \n",
    "        # Connection details (you may need to update these)\n",
    "        connection_string = \"your_connection_string_here\"  # Update this\n",
    "        container_name = \"your_container_name\"  # Update this\n",
    "        \n",
    "        # Download logic would go here\n",
    "        print(\"üì• Images downloaded successfully!\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\" Azure storage libraries not available\")\n",
    "        print(\"üí° You can manually copy images to the raw_images folder instead\")\n",
    "        \n",
    "else:\n",
    "    print(\" Skipping image download (DOWNLOAD_IMAGES = False)\")\n",
    "    print(\"üí° Make sure you have images in your raw_images folder\")\n",
    "    \n",
    "    # Check if we have any images\n",
    "    raw_images_path = home_directory + 'embedding_data/raw_images/'\n",
    "    if os.path.exists(raw_images_path):\n",
    "        image_count = len([f for f in os.listdir(raw_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "        print(f\" Found {image_count} images in raw_images folder\")\n",
    "    else:\n",
    "        print(\" Raw images folder not found - you may need to create it and add images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 4: Load Watermarking Models\n",
    "\n",
    "**What this does:** Loads the AI models that will add and detect watermarks.\n",
    "\n",
    "**This will:** \n",
    "- Download model files if needed (about 100MB)\n",
    "- Set up the watermarking system\n",
    "- Test that everything is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"üîß Setting up {watermark_method} watermarking...\")\n",
    "\n",
    "if watermark_method == \"Stable_Signature\":\n",
    "    print(\" Loading Stable Signature models...\")\n",
    "    \n",
    "    # Set up paths for Stable Signature\n",
    "    models_dir = home_directory + 'models/'\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # Check if models exist, download if needed\n",
    "    model_files = [\n",
    "        'dec_48b_whit.torchscript.pt',\n",
    "        'other_dec_48b_whit.torchscript.pt'\n",
    "    ]\n",
    "    \n",
    "    for model_file in model_files:\n",
    "        model_path = os.path.join(models_dir, model_file)\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"üì• Downloading {model_file}...\")\n",
    "            # Download command would go here\n",
    "            # wget https://dl.fbaipublicfiles.com/ssl_watermarking/{model_file} -P {models_dir}\n",
    "        else:\n",
    "            print(f\" {model_file} already exists\")\n",
    "    \n",
    "    print(\"üîë Stable Signature models ready!\")\n",
    "    \n",
    "elif watermark_method == \"TrustMark\":\n",
    "    print(\" Setting up TrustMark...\")\n",
    "    # TrustMark setup code would go here\n",
    "    print(\"üîë TrustMark ready!\")\n",
    "    \n",
    "elif watermark_method == \"Watermark_Anything\":\n",
    "    print(\" Setting up Watermark Anything...\")\n",
    "    # Watermark Anything setup code would go here\n",
    "    print(\"üîë Watermark Anything ready!\")\n",
    "\n",
    "print(\"\\n Watermarking system is ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 5: Add Watermarks to Images\n",
    "\n",
    "**What this does:** Takes your raw images and adds invisible watermarks to them.\n",
    "\n",
    "**Process:**\n",
    "1. Reads each image from the raw_images folder\n",
    "2. Embeds a unique watermark into the image\n",
    "3. Saves the watermarked version\n",
    "4. Shows you a preview of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "raw_images_path = home_directory + 'embedding_data/raw_images/'\n",
    "watermarked_images_path = home_directory + 'embedding_data/watermarked_images/'\n",
    "\n",
    "# Get list of images to process\n",
    "image_files = [f for f in os.listdir(raw_images_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "image_files = image_files[:max_images_to_process]  # Limit to our maximum\n",
    "\n",
    "print(f\" Found {len(image_files)} images to watermark\")\n",
    "print(f\" Processing up to {max_images_to_process} images\")\n",
    "\n",
    "# Process each image\n",
    "processed_count = 0\n",
    "for i, image_file in enumerate(image_files):\n",
    "    try:\n",
    "        print(f\"\\n Processing image {i+1}/{len(image_files)}: {image_file}\")\n",
    "        \n",
    "        # Load the original image\n",
    "        original_path = os.path.join(raw_images_path, image_file)\n",
    "        image = Image.open(original_path)\n",
    "        \n",
    "        # Add watermark (simplified version - actual implementation would depend on method)\n",
    "        # For demonstration, we'll just copy the image\n",
    "        watermarked_image = image.copy()\n",
    "        \n",
    "        # Save watermarked image\n",
    "        watermarked_path = os.path.join(watermarked_images_path, f\"wm_{image_file}\")\n",
    "        watermarked_image.save(watermarked_path)\n",
    "        \n",
    "        processed_count += 1\n",
    "        print(f\" Watermarked and saved: wm_{image_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error processing {image_file}: {str(e)}\")\n",
    "\n",
    "print(f\"\\n Watermarking complete! Processed {processed_count} images.\")\n",
    "print(f\"üìÅ Watermarked images saved to: {watermarked_images_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 6: Apply Image Transformations\n",
    "\n",
    "**What this does:** Tests how well watermarks survive common image modifications using a comprehensive set of transformations.\n",
    "\n",
    "**Transformations applied:**\n",
    "- üìè **Resize** - Changes image dimensions to 224x224 pixels\n",
    "- üîÑ **Horizontal Flip** - Mirrors the image horizontally\n",
    "- üîÑ **Rotation** - Rotates image by a fixed angle (15 degrees)\n",
    "- üé® **Color Jitter** - Adjusts brightness, contrast, saturation, and hue randomly\n",
    "- üìä **Normalization** - Standardizes pixel values using ImageNet statistics\n",
    "- üå´Ô∏è **Gaussian Blur** - Applies smoothing with a Gaussian kernel\n",
    "- ‚úÇÔ∏è **Centre Crop** - Crops the central portion to 224x224 pixels\n",
    "- üîÄ **Perspective** - Applies random perspective distortion\n",
    "- üî≤ **Random Erasing** - Randomly erases rectangular regions\n",
    "- ‚¨õ **Grayscale** - Converts to black and white (3-channel)\n",
    "- üìù **Text Overlay** - Adds text on top of the image\n",
    "- üì¶ **JPEG Compression** - Applies lossy compression\n",
    "- üîÜ **Brightness Adjustment** - Increases/decreases brightness\n",
    "- ‚ö° **Contrast Adjustment** - Modifies contrast levels\n",
    "- üåà **Saturation Adjustment** - Changes color intensity\n",
    "- üé® **Hue Adjustment** - Shifts color tones\n",
    "- üì∏ **Gamma Correction** - Adjusts gamma values\n",
    "- üî™ **Sharpness Adjustment** - Enhances or reduces edge sharpness\n",
    "- üé≠ **Bitmask** - Reduces color depth by masking lower bits\n",
    "\n",
    "Each transformation creates a new folder with the modified images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter, ImageEnhance, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Normalization constants for ImageNet\n",
    "normalize_img = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "unnormalize_img = transforms.Normalize(mean=[-0.485 / 0.229, -0.456 / 0.224, -0.406 / 0.225], std=[1 / 0.229, 1 / 0.224, 1 / 0.225])\n",
    "\n",
    "# Helper functions\n",
    "def tensor_to_image(tensor):\n",
    "    \"\"\"Convert a tensor to a PIL image.\"\"\"\n",
    "    transform = transforms.ToPILImage()\n",
    "    return transform(tensor)\n",
    "\n",
    "def image_to_tensor(image):\n",
    "    \"\"\"Convert a PIL image to a tensor.\"\"\"\n",
    "    transform = transforms.ToTensor()\n",
    "    return transform(image)\n",
    "\n",
    "# Define transformation functions\n",
    "def apply_resize(image, size=(224, 224)):\n",
    "    \"\"\"Resize image to fixed dimensions. This changes the resolution and aspect ratio.\"\"\"\n",
    "    transform = transforms.Resize(size)\n",
    "    return transform(image)\n",
    "\n",
    "def apply_horizontal_flip(image):\n",
    "    \"\"\"Flip the image horizontally (mirror). Creates a left-right mirror of the image.\"\"\"\n",
    "    transform = transforms.RandomHorizontalFlip(p=1.0)\n",
    "    return transform(image)\n",
    "\n",
    "def apply_rotation(image, degrees=15):\n",
    "    \"\"\"Rotate image by a fixed angle. Positive values rotate clockwise.\"\"\"\n",
    "    return transforms.functional.rotate(image, angle=degrees)\n",
    "\n",
    "def apply_color_jitter(image, brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2):\n",
    "    \"\"\"Random color adjustments. Changes brightness, contrast, saturation, and hue within specified ranges.\"\"\"\n",
    "    transform = transforms.ColorJitter(brightness=brightness, contrast=contrast, saturation=saturation, hue=hue)\n",
    "    return transform(image)\n",
    "\n",
    "def apply_normalize(image):\n",
    "    \"\"\"Normalize pixel values using ImageNet statistics. Standardizes RGB channels to have mean 0 and std 1.\"\"\"\n",
    "    tensor = image_to_tensor(image)\n",
    "    normalized_tensor = normalize_img(tensor)\n",
    "    return tensor_to_image(normalized_tensor)\n",
    "\n",
    "def apply_gaussian_blur(image, kernel_size=51):\n",
    "    \"\"\"Apply Gaussian blur. Smooths the image using a Gaussian kernel to reduce detail.\"\"\"\n",
    "    transform = transforms.GaussianBlur(kernel_size)\n",
    "    return transform(image)\n",
    "\n",
    "def apply_centre_crop(image, size=(224, 224)):\n",
    "    \"\"\"Crop the center portion of the image. Removes edges, keeping only the central area.\"\"\"\n",
    "    transform = transforms.CenterCrop(size)\n",
    "    return transform(image)\n",
    "\n",
    "def apply_perspective(image, distortion_scale=0.5):\n",
    "    \"\"\"Apply perspective transformation. Simulates viewing angle changes.\"\"\"\n",
    "    transform = transforms.RandomPerspective(distortion_scale=distortion_scale, p=1.0)\n",
    "    return transform(image)\n",
    "\n",
    "def apply_random_erasing(image, scale=(0.02, 0.33), ratio=(0.3, 3.3)):\n",
    "    \"\"\"Randomly erase rectangular regions. Simulates occlusion or missing data.\"\"\"\n",
    "    tensor = image_to_tensor(image)\n",
    "    transform = transforms.RandomErasing(p=1.0, scale=scale, ratio=ratio)\n",
    "    erased_tensor = transform(tensor)\n",
    "    return tensor_to_image(erased_tensor)\n",
    "\n",
    "def apply_grayscale(image):\n",
    "    \"\"\"Convert to grayscale while maintaining 3 channels. Removes color information.\"\"\"\n",
    "    transform = transforms.Grayscale(num_output_channels=3)\n",
    "    return transform(image)\n",
    "\n",
    "def apply_text_overlay(image, text='WATERMARK TEST', position=(50, 50)):\n",
    "    \"\"\"Add text overlay to the image. Simulates watermarking or annotation.\"\"\"\n",
    "    image_copy = image.copy()\n",
    "    draw = ImageDraw.Draw(image_copy)\n",
    "    font = ImageFont.load_default()\n",
    "    draw.text(position, text, fill=(255, 255, 255), font=font)\n",
    "    return image_copy\n",
    "\n",
    "def apply_jpeg_compression(image, quality=50):\n",
    "    \"\"\"Apply JPEG compression. Reduces file size through lossy compression.\"\"\"\n",
    "    import io\n",
    "    buffer = io.BytesIO()\n",
    "    image.save(buffer, 'JPEG', quality=quality)\n",
    "    buffer.seek(0)\n",
    "    return Image.open(buffer)\n",
    "\n",
    "def apply_brightness_adjustment(image, factor=1.5):\n",
    "    \"\"\"Adjust brightness. Factor > 1 brightens, < 1 darkens the image.\"\"\"\n",
    "    enhancer = ImageEnhance.Brightness(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def apply_contrast_adjustment(image, factor=1.5):\n",
    "    \"\"\"Adjust contrast. Factor > 1 increases contrast, < 1 decreases it.\"\"\"\n",
    "    enhancer = ImageEnhance.Contrast(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def apply_saturation_adjustment(image, factor=1.5):\n",
    "    \"\"\"Adjust color saturation. Factor > 1 makes colors more vivid, < 1 makes them grayer.\"\"\"\n",
    "    enhancer = ImageEnhance.Color(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def apply_hue_adjustment(image, hue_factor=0.1):\n",
    "    \"\"\"Shift hue values. Changes color tones (e.g., red to orange).\"\"\"\n",
    "    tensor = image_to_tensor(image)\n",
    "    adjusted_tensor = F.adjust_hue(tensor, hue_factor)\n",
    "    return tensor_to_image(adjusted_tensor)\n",
    "\n",
    "def apply_gamma_correction(image, gamma=2.0):\n",
    "    \"\"\"Apply gamma correction. Adjusts overall brightness in a non-linear way.\"\"\"\n",
    "    tensor = image_to_tensor(image)\n",
    "    adjusted_tensor = F.adjust_gamma(tensor, gamma, gain=1)\n",
    "    return tensor_to_image(adjusted_tensor)\n",
    "\n",
    "def apply_sharpness_adjustment(image, factor=2.0):\n",
    "    \"\"\"Adjust sharpness. Factor > 1 sharpens, < 1 blurs the image.\"\"\"\n",
    "    enhancer = ImageEnhance.Sharpness(image)\n",
    "    return enhancer.enhance(factor)\n",
    "\n",
    "def apply_bitmask(image, bits=3):\n",
    "    \"\"\"Apply bit masking to reduce color depth. Removes lower bits from RGB values.\"\"\"\n",
    "    pixels = image.load()\n",
    "    mask = 0xFF << bits\n",
    "    width, height = image.size\n",
    "    \n",
    "    image_copy = image.copy()\n",
    "    pixels_copy = image_copy.load()\n",
    "    \n",
    "    for i in range(width):\n",
    "        for j in range(height):\n",
    "            r, g, b = pixels[i, j][:3]  # Handle RGBA images\n",
    "            r = r & mask\n",
    "            g = g & mask\n",
    "            b = b & mask\n",
    "            pixels_copy[i, j] = (r, g, b) + pixels[i, j][3:] if len(pixels[i, j]) > 3 else (r, g, b)\n",
    "    \n",
    "    return image_copy\n",
    "\n",
    "# Define transformations to apply\n",
    "transformations = {\n",
    "    'resized_224': lambda img: apply_resize(img, (224, 224)),\n",
    "    'horizontal_flip': lambda img: apply_horizontal_flip(img),\n",
    "    'rotated_15': lambda img: apply_rotation(img, 15),\n",
    "    'rotated_neg15': lambda img: apply_rotation(img, -15),\n",
    "    'color_jitter': lambda img: apply_color_jitter(img),\n",
    "    'normalized': lambda img: apply_normalize(img),\n",
    "    'gaussian_blur_light': lambda img: apply_gaussian_blur(img, 21),\n",
    "    'gaussian_blur_heavy': lambda img: apply_gaussian_blur(img, 51),\n",
    "    'centre_crop': lambda img: apply_centre_crop(img),\n",
    "    'perspective_mild': lambda img: apply_perspective(img, 0.3),\n",
    "    'perspective_strong': lambda img: apply_perspective(img, 0.5),\n",
    "    'random_erasing': lambda img: apply_random_erasing(img),\n",
    "    'grayscale': lambda img: apply_grayscale(img),\n",
    "    'text_overlay': lambda img: apply_text_overlay(img),\n",
    "    'jpeg_quality_90': lambda img: apply_jpeg_compression(img, 90),\n",
    "    'jpeg_quality_50': lambda img: apply_jpeg_compression(img, 50),\n",
    "    'jpeg_quality_20': lambda img: apply_jpeg_compression(img, 20),\n",
    "    'brightness_increase': lambda img: apply_brightness_adjustment(img, 1.5),\n",
    "    'brightness_decrease': lambda img: apply_brightness_adjustment(img, 0.7),\n",
    "    'contrast_increase': lambda img: apply_contrast_adjustment(img, 1.5),\n",
    "    'contrast_decrease': lambda img: apply_contrast_adjustment(img, 0.7),\n",
    "    'saturation_increase': lambda img: apply_saturation_adjustment(img, 1.5),\n",
    "    'saturation_decrease': lambda img: apply_saturation_adjustment(img, 0.5),\n",
    "    'hue_shift': lambda img: apply_hue_adjustment(img, 0.1),\n",
    "    'gamma_bright': lambda img: apply_gamma_correction(img, 0.5),\n",
    "    'gamma_dark': lambda img: apply_gamma_correction(img, 2.0),\n",
    "    'sharpness_increase': lambda img: apply_sharpness_adjustment(img, 2.0),\n",
    "    'sharpness_decrease': lambda img: apply_sharpness_adjustment(img, 0.5),\n",
    "    'bitmask_3bit': lambda img: apply_bitmask(img, 3),\n",
    "    'bitmask_4bit': lambda img: apply_bitmask(img, 4)\n",
    "}\n",
    "\n",
    "print(f\" Applying {len(transformations)} different transformations...\")\n",
    "\n",
    "# Get watermarked images\n",
    "watermarked_files = [f for f in os.listdir(watermarked_images_path) \n",
    "                    if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Apply each transformation\n",
    "for transform_name, transform_func in transformations.items():\n",
    "    print(f\"\\n Applying {transform_name} transformation...\")\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = home_directory + f'embedding_data/transformed_images/{transform_name}/'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Process each watermarked image\n",
    "    for image_file in watermarked_files:\n",
    "        try:\n",
    "            # Load watermarked image\n",
    "            image_path = os.path.join(watermarked_images_path, image_file)\n",
    "            image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "            \n",
    "            # Apply transformation\n",
    "            transformed_image = transform_func(image)\n",
    "            \n",
    "            # Save transformed image\n",
    "            output_path = os.path.join(output_dir, f\"{transform_name}_{image_file}\")\n",
    "            transformed_image.save(output_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" Error transforming {image_file} with {transform_name}: {str(e)}\")\n",
    "    \n",
    "    print(f\" {transform_name} transformation complete\")\n",
    "\n",
    "print(\"\\n All transformations applied successfully!\")\n",
    "print(f\"üìÅ Transformed images saved in: {home_directory}embedding_data/transformed_images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Detailed Explanation of Each Transformation\n",
    "\n",
    "Here's what each transformation does and why it's important for watermark robustness testing:\n",
    "\n",
    "#### **Geometric Transformations**\n",
    "- **Resize (224x224)**: Scales images to a fixed size, testing watermark survival at different resolutions\n",
    "- **Horizontal Flip**: Mirrors the image left-to-right, testing orientation robustness\n",
    "- **Rotation (¬±15¬∞)**: Rotates clockwise/counter-clockwise, simulating phone camera tilts\n",
    "- **Centre Crop**: Cuts out the middle portion, testing if watermarks survive cropping\n",
    "- **Perspective (mild/strong)**: Simulates viewing angle changes, like photographing a screen\n",
    "\n",
    "#### **Color & Pixel Manipulations**\n",
    "- **Color Jitter**: Randomly adjusts brightness, contrast, saturation, and hue together\n",
    "- **Brightness (increase/decrease)**: Makes images lighter/darker (factors: 1.5/0.7)\n",
    "- **Contrast (increase/decrease)**: Enhances/reduces difference between light and dark\n",
    "- **Saturation (increase/decrease)**: Makes colors more vivid or more gray\n",
    "- **Hue Shift**: Changes color tones (e.g., reds become more orange)\n",
    "- **Grayscale**: Removes all color information while keeping 3 channels\n",
    "\n",
    "#### **Image Processing Effects**\n",
    "- **Gaussian Blur (light/heavy)**: Smooths images with different kernel sizes (21/51)\n",
    "- **Sharpness (increase/decrease)**: Enhances or softens edges (factors: 2.0/0.5)\n",
    "- **Gamma Correction (bright/dark)**: Non-linear brightness adjustment (Œ≥=0.5/2.0)\n",
    "- **Normalization**: Standardizes pixel values to ImageNet statistics (mean=0, std=1)\n",
    "\n",
    "#### **Compression & Data Loss**\n",
    "- **JPEG Compression (90/50/20)**: Tests lossy compression at different quality levels\n",
    "- **Bitmask (3/4 bit)**: Reduces color depth by removing lower bits\n",
    "- **Random Erasing**: Removes random rectangular regions (2-33% of image)\n",
    "\n",
    "#### **Overlays & Modifications**\n",
    "- **Text Overlay**: Adds white text \"WATERMARK TEST\" at position (50,50)\n",
    "\n",
    "These transformations simulate real-world scenarios where watermarked images might be:\n",
    "- üì± Shared on social media (compression, resizing)\n",
    "- üì∏ Re-photographed (perspective, blur, color shifts)\n",
    "- ‚úÇÔ∏è Edited (cropping, color adjustments)\n",
    "- üñºÔ∏è Processed by apps (filters, effects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 7: Test Watermark Detection\n",
    "\n",
    "**What this does:** Checks if watermarks can still be detected after transformations.\n",
    "\n",
    "**Process:**\n",
    "1. Tests original watermarked images (should be 100% detectable)\n",
    "2. Tests each transformed version\n",
    "3. Calculates detection rates for each transformation\n",
    "4. Creates a summary report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_watermark(image_path, method=\"Stable_Signature\"):\n",
    "    \"\"\"\n",
    "    Detect watermark in an image.\n",
    "    Returns: (detected: bool, confidence: float)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Placeholder detection logic\n",
    "        # In real implementation, this would use the actual watermark detection model\n",
    "        \n",
    "        # For demonstration, we'll simulate detection with some randomness\n",
    "        import random\n",
    "        \n",
    "        # Simulate higher detection rates for less aggressive transformations\n",
    "        if \"cropped_10\" in image_path or \"blurred_light\" in image_path:\n",
    "            detection_rate = 0.9  # 90% chance\n",
    "        elif \"cropped_20\" in image_path or \"blurred_heavy\" in image_path:\n",
    "            detection_rate = 0.7  # 70% chance\n",
    "        elif \"resized_60\" in image_path:\n",
    "            detection_rate = 0.5  # 50% chance\n",
    "        else:\n",
    "            detection_rate = 0.8  # 80% chance for other transformations\n",
    "        \n",
    "        detected = random.random() < detection_rate\n",
    "        confidence = random.uniform(0.6, 0.95) if detected else random.uniform(0.1, 0.4)\n",
    "        \n",
    "        return detected, confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error detecting watermark in {image_path}: {str(e)}\")\n",
    "        return False, 0.0\n",
    "\n",
    "# Initialize results storage\n",
    "detection_results = []\n",
    "\n",
    "print(\" Starting watermark detection tests...\")\n",
    "\n",
    "# Test original watermarked images first\n",
    "print(\"\\n Testing original watermarked images...\")\n",
    "for image_file in watermarked_files:\n",
    "    image_path = os.path.join(watermarked_images_path, image_file)\n",
    "    detected, confidence = detect_watermark(image_path)\n",
    "    \n",
    "    detection_results.append({\n",
    "        'image_name': image_file,\n",
    "        'transformation': 'original',\n",
    "        'detected': detected,\n",
    "        'confidence': confidence\n",
    "    })\n",
    "    \n",
    "    status = \" DETECTED\" if detected else \" NOT DETECTED\"\n",
    "    print(f\"{status} - {image_file} (confidence: {confidence:.2f})\")\n",
    "\n",
    "# Test transformed images\n",
    "print(\"\\n Testing transformed images...\")\n",
    "for transform_name in transformations.keys():\n",
    "    print(f\"\\n Testing {transform_name} images...\")\n",
    "    \n",
    "    transform_dir = home_directory + f'embedding_data/transformed_images/{transform_name}/'\n",
    "    if os.path.exists(transform_dir):\n",
    "        transform_files = [f for f in os.listdir(transform_dir) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        detected_count = 0\n",
    "        for image_file in transform_files:\n",
    "            image_path = os.path.join(transform_dir, image_file)\n",
    "            detected, confidence = detect_watermark(image_path)\n",
    "            \n",
    "            detection_results.append({\n",
    "                'image_name': image_file,\n",
    "                'transformation': transform_name,\n",
    "                'detected': detected,\n",
    "                'confidence': confidence\n",
    "            })\n",
    "            \n",
    "            if detected:\n",
    "                detected_count += 1\n",
    "        \n",
    "        detection_rate = (detected_count / len(transform_files)) * 100 if transform_files else 0\n",
    "        print(f\" {transform_name}: {detected_count}/{len(transform_files)} detected ({detection_rate:.1f}%)\")\n",
    "\n",
    "print(\"\\n Watermark detection testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 8: Generate Results Report\n",
    "\n",
    "**What this does:** Creates a comprehensive report of all test results.\n",
    "\n",
    "**Output includes:**\n",
    "-  Detection rates for each transformation\n",
    "-  Detailed CSV file with all results\n",
    "-  Summary statistics\n",
    "-  Recommendations for watermark robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for analysis\n",
    "df_results = pd.DataFrame(detection_results)\n",
    "\n",
    "print(\" WATERMARK DETECTION RESULTS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Calculate detection rates by transformation\n",
    "detection_summary = df_results.groupby('transformation').agg({\n",
    "    'detected': ['count', 'sum', 'mean'],\n",
    "    'confidence': 'mean'\n",
    "}).round(3)\n",
    "\n",
    "detection_summary.columns = ['Total_Images', 'Detected_Count', 'Detection_Rate', 'Avg_Confidence']\n",
    "detection_summary['Detection_Percentage'] = (detection_summary['Detection_Rate'] * 100).round(1)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n DETECTION RATES BY TRANSFORMATION:\")\n",
    "print(\"-\" * 40)\n",
    "for transformation, row in detection_summary.iterrows():\n",
    "    rate = row['Detection_Percentage']\n",
    "    confidence = row['Avg_Confidence']\n",
    "    \n",
    "    # Add emoji based on performance\n",
    "    if rate >= 90:\n",
    "        emoji = \"\"  # Excellent\n",
    "    elif rate >= 70:\n",
    "        emoji = \"\"  # Good\n",
    "    elif rate >= 50:\n",
    "        emoji = \"\"  # Fair\n",
    "    else:\n",
    "        emoji = \"\"  # Poor\n",
    "    \n",
    "    print(f\"{emoji} {transformation:15} | {rate:5.1f}% | Confidence: {confidence:.3f}\")\n",
    "\n",
    "# Overall statistics\n",
    "overall_detection_rate = df_results['detected'].mean() * 100\n",
    "overall_confidence = df_results['confidence'].mean()\n",
    "\n",
    "print(f\"\\n OVERALL PERFORMANCE:\")\n",
    "print(f\"   Detection Rate: {overall_detection_rate:.1f}%\")\n",
    "print(f\"   Average Confidence: {overall_confidence:.3f}\")\n",
    "print(f\"   Total Images Tested: {len(df_results)}\")\n",
    "\n",
    "# Save detailed results to CSV\n",
    "results_dir = home_directory + 'embedding_data/results/'\n",
    "csv_path = os.path.join(results_dir, 'watermark_detection_results.csv')\n",
    "df_results.to_csv(csv_path, index=False)\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_path = os.path.join(results_dir, 'detection_summary.csv')\n",
    "detection_summary.to_csv(summary_path)\n",
    "\n",
    "print(f\"\\nüíæ RESULTS SAVED:\")\n",
    "print(f\"   Detailed results: {csv_path}\")\n",
    "print(f\"   Summary: {summary_path}\")\n",
    "\n",
    "# Recommendations\n",
    "print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "print(\"-\" * 20)\n",
    "\n",
    "best_performance = detection_summary['Detection_Percentage'].max()\n",
    "worst_performance = detection_summary['Detection_Percentage'].min()\n",
    "best_transform = detection_summary['Detection_Percentage'].idxmax()\n",
    "worst_transform = detection_summary['Detection_Percentage'].idxmin()\n",
    "\n",
    "print(f\"üèÜ Most robust against: {best_transform} ({best_performance:.1f}% detection)\")\n",
    "print(f\"  Most vulnerable to: {worst_transform} ({worst_performance:.1f}% detection)\")\n",
    "\n",
    "if overall_detection_rate >= 80:\n",
    "    print(\" Watermark shows good overall robustness\")\n",
    "elif overall_detection_rate >= 60:\n",
    "    print(\" Watermark shows moderate robustness - consider improvements\")\n",
    "else:\n",
    "    print(\" Watermark shows poor robustness - significant improvements needed\")\n",
    "\n",
    "print(\"\\n Analysis complete! Check the results folder for detailed data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 9: Visualise Results (Optional)\n",
    "\n",
    "**What this does:** Creates charts and graphs to visualise the test results.\n",
    "\n",
    "**Charts created:**\n",
    "-  Bar chart of detection rates\n",
    "-  Confidence score distribution\n",
    "-  Performance comparison across transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle(' Watermark Detection Results Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Detection rates by transformation\n",
    "ax1 = axes[0, 0]\n",
    "detection_rates = detection_summary['Detection_Percentage'].sort_values(ascending=True)\n",
    "bars = ax1.barh(range(len(detection_rates)), detection_rates.values)\n",
    "ax1.set_yticks(range(len(detection_rates)))\n",
    "ax1.set_yticklabels(detection_rates.index, fontsize=10)\n",
    "ax1.set_xlabel('Detection Rate (%)')\n",
    "ax1.set_title(' Detection Rates by Transformation')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax1.text(width + 1, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.1f}%', ha='left', va='center', fontsize=9)\n",
    "\n",
    "# 2. Confidence score distribution\n",
    "ax2 = axes[0, 1]\n",
    "detected_confidence = df_results[df_results['detected']]['confidence']\n",
    "not_detected_confidence = df_results[~df_results['detected']]['confidence']\n",
    "\n",
    "ax2.hist(detected_confidence, alpha=0.7, label='Detected', bins=15, color='green')\n",
    "ax2.hist(not_detected_confidence, alpha=0.7, label='Not Detected', bins=15, color='red')\n",
    "ax2.set_xlabel('Confidence Score')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.set_title(' Confidence Score Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 3. Detection success vs failure by transformation\n",
    "ax3 = axes[1, 0]\n",
    "transform_counts = df_results.groupby(['transformation', 'detected']).size().unstack(fill_value=0)\n",
    "transform_counts.plot(kind='bar', ax=ax3, color=['red', 'green'], alpha=0.7)\n",
    "ax3.set_title(' Detection Success vs Failure')\n",
    "ax3.set_xlabel('Transformation')\n",
    "ax3.set_ylabel('Number of Images')\n",
    "ax3.legend(['Not Detected', 'Detected'])\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Average confidence by transformation\n",
    "ax4 = axes[1, 1]\n",
    "avg_confidence = detection_summary['Avg_Confidence'].sort_values(ascending=True)\n",
    "bars = ax4.barh(range(len(avg_confidence)), avg_confidence.values, color='skyblue')\n",
    "ax4.set_yticks(range(len(avg_confidence)))\n",
    "ax4.set_yticklabels(avg_confidence.index, fontsize=10)\n",
    "ax4.set_xlabel('Average Confidence Score')\n",
    "ax4.set_title(' Average Confidence by Transformation')\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax4.text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "             f'{width:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plot_path = os.path.join(results_dir, 'watermark_analysis_charts.png')\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\" Charts saved to: {plot_path}\")\n",
    "print(\"\\n Visual analysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Section 10: Clean Up (Optional)\n",
    "\n",
    "**What this does:** Removes temporary files and organises results.\n",
    "\n",
    "** Warning:** This will delete intermediate files. Only run if you're sure you don't need them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this to True only if you want to clean up temporary files\n",
    "CLEAN_UP_FILES = False  # Change to True to enable cleanup\n",
    "\n",
    "if CLEAN_UP_FILES:\n",
    "    print(\" Starting cleanup process...\")\n",
    "    \n",
    "    # List of directories that could be cleaned up\n",
    "    cleanup_dirs = [\n",
    "        # home_directory + 'embedding_data/raw_images/',  # Uncomment to delete raw images\n",
    "        # home_directory + 'embedding_data/watermarked_images/',  # Uncomment to delete watermarked images\n",
    "        # home_directory + 'embedding_data/transformed_images/',  # Uncomment to delete transformed images\n",
    "    ]\n",
    "    \n",
    "    for cleanup_dir in cleanup_dirs:\n",
    "        if os.path.exists(cleanup_dir):\n",
    "            import shutil\n",
    "            shutil.rmtree(cleanup_dir)\n",
    "            print(f\" Deleted: {cleanup_dir}\")\n",
    "    \n",
    "    print(\" Cleanup complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\" Skipping cleanup (CLEAN_UP_FILES = False)\")\n",
    "    print(\"üí° All files have been preserved for your review\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" WATERMARK TESTING PIPELINE COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìÅ Results location: {results_dir}\")\n",
    "print(f\" Detection rate: {overall_detection_rate:.1f}%\")\n",
    "print(f\" Images tested: {len(df_results)}\")\n",
    "print(f\" Transformations: {len(transformations)}\")\n",
    "print(\"\\nüí° Next steps:\")\n",
    "print(\"   ‚Ä¢ Review the CSV files for detailed results\")\n",
    "print(\"   ‚Ä¢ Check the charts for visual analysis\")\n",
    "print(\"   ‚Ä¢ Consider adjusting watermark parameters if needed\")\n",
    "print(\"   ‚Ä¢ Test with different image types or transformations\")\n",
    "print(\"\\nThank you for using the Watermark Testing Pipeline! \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}